{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e546fe-1f5c-4421-a0e1-96772455172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import \"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import warnings\n",
    "import dataclasses\n",
    "import plotly.express\n",
    "import plotly.subplots\n",
    "import plotly.graph_objects\n",
    "import ipywidgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import src\n",
    "\n",
    "if torch.cuda.is_available(): device = \"cuda\"\n",
    "elif torch.backends.mps.is_available(): device = \"mps\"\n",
    "else: device = \"cpu\"\n",
    "\n",
    "# disable MPS UserWarning: The operator 'aten::col2im' is not currently \n",
    "# supported on the MPS backend\n",
    "warnings.filterwarnings(\"ignore\", message=\".*MPS.*fallback.*\")\n",
    "\n",
    "def ckptFinder(config: src.config.Config, epoch: int | None = None) -> str:\n",
    "    root = config.trainer.ckpt_save_fold\n",
    "    name = config.__class__.__name__\n",
    "    target = \"last\" if epoch is None else f\"epoch={epoch}\"\n",
    "    for f in os.listdir(os.path.join(root, name)):\n",
    "        if target in f and f.endswith(\".ckpt\"):\n",
    "            return os.path.join(root, name, f)\n",
    "    raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386db26-72ba-4174-97f7-f3c34d985980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ckpt from ckpt/ConfigE01/last.ckpt\n"
     ]
    }
   ],
   "source": [
    "\"\"\" config \"\"\"\n",
    "\n",
    "config = src.config.ConfigE01()     # .data and .model will be used\n",
    "config.trainer.ckpt_load_path = ckptFinder(config, epoch=None)\n",
    "print(f\"load ckpt from {config.trainer.ckpt_load_path}\")\n",
    "# for prediction save & load\n",
    "result_fold = f\"data/{config.__class__.__name__}/\"\n",
    "result_path = os.path.join(result_fold, \"result.pt\")\n",
    "sample_path = os.path.join(result_fold, \"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907bcc2-1210-446b-8026-d9d8b1381c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:28<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: pd.DataFrame > data/ConfigE01/sample.csv\t(21592, 13)\n",
      "result: torch.Tensor > data/ConfigE01/result.pt\t\t(21592, 7, 1000)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" prediction \"\"\"\n",
    "\n",
    "# load data\n",
    "x = torch.load(\n",
    "    os.path.join(config.data.data_load_fold, 'x.pt'), weights_only=True\n",
    ")\n",
    "# normalize each channel\n",
    "mean = torch.nanmean(x, dim=(0, 2))\n",
    "mean2 = torch.nanmean(x * x, dim=(0, 2))\n",
    "std = torch.sqrt(mean2 - mean * mean)\n",
    "x = (x - mean.view(1, -1, 1)) / std.view(1, -1, 1)\n",
    "# sample profile\n",
    "sample = pd.read_csv(os.path.join(config.data.data_load_fold, \"sample.csv\"))\n",
    "sample = sample.drop(columns=[\"split02\"])\n",
    "sample = sample.rename(columns={\"split01\": \"split\"})\n",
    "sample[\"split\"] = sample[\"split\"].map({0: \"train\", 1: \"test\", 2: \"test\"})\n",
    "sample[\"system\"] = sample[\"system\"].map({False: \"old\", True: \"new\"})\n",
    "# filter valid samples\n",
    "valid = torch.where(~torch.isnan(x).any(dim=(1, 2)))[0]\n",
    "x = x[valid]\n",
    "sample = sample.iloc[valid.numpy()].reset_index(drop=True)\n",
    "# data\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    src.data.RawDataset(x), \n",
    "    batch_size=config.data.batch_size, shuffle=False, \n",
    ")\n",
    "# model\n",
    "model = src.model.SCOST(**dataclasses.asdict(config.model))\n",
    "ckpt = torch.load(\n",
    "    config.trainer.ckpt_load_path, weights_only=True, \n",
    "    map_location=torch.device(device)\n",
    ")\n",
    "state_dict = {\n",
    "    k.replace(\"model.\", \"\"): v for k, v in ckpt[\"state_dict\"].items()\n",
    "    if k.startswith(\"model.\")\n",
    "}\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model = model.eval().to(device)\n",
    "# predict\n",
    "result_b = []\n",
    "for batch in tqdm.tqdm(dataloader):\n",
    "    # batch to device\n",
    "    x, channel_idx = batch\n",
    "    x, channel_idx = x.to(device), channel_idx.to(device)\n",
    "    # forward\n",
    "    with torch.no_grad(): x_pred, _ = model.forwardReconstructionRaw(\n",
    "        x, channel_idx, user_mask=3\n",
    "    )\n",
    "    # store result\n",
    "    result_b.append(torch.cat([\n",
    "        x.detach().cpu(),                               # (B, 4, T)\n",
    "        x_pred[:, 3, :].detach().cpu().unsqueeze(1)     # (B, 1, T)\n",
    "    ], dim=1))\n",
    "result = torch.cat(result_b, dim=0)            # (N, 5, T)\n",
    "# map bp in 3nd and 4th channel to waveform before normalization\n",
    "# and store new waveform in 5th and 6th channel\n",
    "result = torch.cat([\n",
    "    result, \n",
    "    (result[:, 3, :] * std[3] + mean[3]).unsqueeze(1),\n",
    "    (result[:, 4, :] * std[3] + mean[3]).unsqueeze(1),\n",
    "], dim=1).detach().cpu()\n",
    "# store key features in profile\n",
    "sample[\"TrueMinBP\"] = result[:, 5].min(dim=1).values.numpy()\n",
    "sample[\"TrueMaxBP\"] = result[:, 5].max(dim=1).values.numpy()\n",
    "sample[\"PredMinBP\"] = result[:, 6].min(dim=1).values.numpy()\n",
    "sample[\"PredMaxBP\"] = result[:, 6].max(dim=1).values.numpy()\n",
    "sample[\"(P-T)MinBP\"] = sample[\"PredMinBP\"] - sample[\"TrueMinBP\"]\n",
    "sample[\"(P-T)MaxBP\"] = sample[\"PredMaxBP\"] - sample[\"TrueMaxBP\"]\n",
    "# save result as .pt and sample as .csv in result_save_fold\n",
    "# print shape and where saved\n",
    "os.makedirs(result_fold, exist_ok=True)\n",
    "torch.save(result, result_path)\n",
    "sample.to_csv(sample_path, index=False)\n",
    "print(f\"sample: pd.DataFrame > {sample_path}\\t{sample.shape}\")\n",
    "print(f\"result: torch.Tensor > {result_path}\\t\\t{tuple(result.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d325ac-496d-4509-af91-21b52b9b7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load \"\"\"\n",
    "\n",
    "result = torch.load(result_path, weights_only=True)\n",
    "sample = pd.read_csv(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae128879-86f0-4342-a694-0587fdf6bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration 0\n",
      "train \tMAE of (min, max) = ( 3.95,  5.77)\n",
      "test \tMAE of (min, max) = (15.03, 22.27)\n",
      "calibration 1\n",
      "train \tMAE of (min, max) = ( 8.65, 10.65)\n",
      "test \tMAE of (min, max) = (12.25, 20.29)\n",
      "calibration 2\n",
      "train \tMAE of (min, max) = ( 4.03,  5.78)\n",
      "test \tMAE of (min, max) = (11.79, 18.67)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" calibration \"\"\"\n",
    "\n",
    "# region # calibration 0: no calibration\n",
    "print(\"calibration 0\")\n",
    "for s in [\"train\", \"test\"]: print(\n",
    "    s, \"\\tMAE of (min, max) = ({:5.2f}, {:5.2f})\".format(\n",
    "        np.nanmean(np.abs(\n",
    "            sample[\n",
    "                (sample[\"split\"] == s) & (sample[\"condition\"] != 1)\n",
    "            ][\"(P-T)MinBP\"]\n",
    "        )),\n",
    "        np.nanmean(np.abs(\n",
    "            sample[\n",
    "                (sample[\"split\"] == s) & (sample[\"condition\"] != 1)\n",
    "            ][\"(P-T)MaxBP\"]\n",
    "        )),\n",
    "    )\n",
    ")\n",
    "# endregion\n",
    "\n",
    "# region # calibration 1: a and b per subject and min/max\n",
    "sample[\"Cal1PredMinBP\"]  = np.nan\n",
    "sample[\"Cal1PredMaxBP\"]  = np.nan\n",
    "sample[\"(Cal1P-T)MinBP\"] = np.nan\n",
    "sample[\"(Cal1P-T)MaxBP\"] = np.nan\n",
    "for subject, group in sample.groupby(\"subject\"):\n",
    "    # calibration subset: condition == 1\n",
    "    cond1 = group[group[\"condition\"] == 1]\n",
    "    # fit linear models if enough calibration points\n",
    "    if len(cond1) < 2:\n",
    "        # Not enough calibration points: no correction\n",
    "        a_min, b_min = 0.0, 0.0   # error ≈ 0 → P_adj = P\n",
    "        a_max, b_max = 0.0, 0.0\n",
    "    else:\n",
    "        # Min BP: fit PredMinBP -> (P-T)MinBP\n",
    "        a_min, b_min, r_value, p_value, std_err = scipy.stats.linregress(\n",
    "            cond1[\"PredMinBP\"], cond1[\"(P-T)MinBP\"]\n",
    "        )\n",
    "        # Max BP: fit PredMaxBP -> (P-T)MaxBP\n",
    "        a_max, b_max, r_value, p_value, std_err = scipy.stats.linregress(\n",
    "            cond1[\"PredMaxBP\"], cond1[\"(P-T)MaxBP\"]\n",
    "        )\n",
    "    # indices of this subject in the original DataFrame\n",
    "    idx = group.index\n",
    "    # Apply this subject's correction to all its rows\n",
    "    pred_min = sample.loc[idx, \"PredMinBP\"]\n",
    "    pred_max = sample.loc[idx, \"PredMaxBP\"]\n",
    "    true_min = sample.loc[idx, \"TrueMinBP\"]\n",
    "    true_max = sample.loc[idx, \"TrueMaxBP\"]\n",
    "    # Predicted error from linear model\n",
    "    err_hat_min = a_min * pred_min + b_min  # type: ignore\n",
    "    err_hat_max = a_max * pred_max + b_max  # type: ignore\n",
    "    # Corrected predictions: P_adj = P - (aP + b)\n",
    "    adj_pred_min = pred_min - err_hat_min\n",
    "    adj_pred_max = pred_max - err_hat_max\n",
    "    # stre\n",
    "    sample.loc[idx, \"Cal1PredMinBP\"]  = adj_pred_min\n",
    "    sample.loc[idx, \"Cal1PredMaxBP\"]  = adj_pred_max\n",
    "    sample.loc[idx, \"(Cal1P-T)MinBP\"] = adj_pred_min - true_min\n",
    "    sample.loc[idx, \"(Cal1P-T)MaxBP\"] = adj_pred_max - true_max\n",
    "print(\"calibration 1\")\n",
    "for s in [\"train\", \"test\"]: print(\n",
    "    s, \"\\tMAE of (min, max) = ({:5.2f}, {:5.2f})\".format(\n",
    "        np.nanmean(np.abs(\n",
    "            sample[\n",
    "                (sample[\"split\"] == s) & (sample[\"condition\"] != 1)\n",
    "            ][\"(Cal1P-T)MinBP\"]\n",
    "        )),\n",
    "        np.nanmean(np.abs(\n",
    "            sample[\n",
    "                (sample[\"split\"] == s) & (sample[\"condition\"] != 1)\n",
    "            ][\"(Cal1P-T)MaxBP\"]\n",
    "        )),\n",
    "    )\n",
    ")\n",
    "# endregion\n",
    "\n",
    "# region # calibration 2: a per split and min/max, b per subject and min/max\n",
    "# 2.0 prepare columns for second calibration\n",
    "sample[\"Cal2PredMinBP\"]  = np.nan\n",
    "sample[\"Cal2PredMaxBP\"]  = np.nan\n",
    "sample[\"(Cal2P-T)MinBP\"] = np.nan\n",
    "sample[\"(Cal2P-T)MaxBP\"] = np.nan\n",
    "# 2.1 compute global slopes for each split (train / test)\n",
    "global_slopes = {}  # keys: (split, \"min\") / (split, \"max\")\n",
    "for split_name in [\"train\", \"test\"]:\n",
    "    df_split = sample[\n",
    "        (sample[\"split\"] == split_name) & (sample[\"condition\"] == 1)\n",
    "    ]\n",
    "    # Min BP: PredMinBP -> (P-T)MinBP\n",
    "    if df_split[\"PredMinBP\"].notna().sum() >= 2:\n",
    "        a_min, b_min, r, p, se = scipy.stats.linregress(\n",
    "            df_split[\"PredMinBP\"], df_split[\"(P-T)MinBP\"]\n",
    "        )\n",
    "    else:\n",
    "        a_min = 0.0  # no slope info; treat as pure bias\n",
    "    global_slopes[(split_name, \"min\")] = a_min\n",
    "    # Max BP: PredMaxBP -> (P-T)MaxBP\n",
    "    if df_split[\"PredMaxBP\"].notna().sum() >= 2:\n",
    "        a_max, b_max, r, p, se = scipy.stats.linregress(\n",
    "            df_split[\"PredMaxBP\"], df_split[\"(P-T)MaxBP\"]\n",
    "        )\n",
    "    else:\n",
    "        a_max = 0.0\n",
    "    global_slopes[(split_name, \"max\")] = a_max\n",
    "# 2.2 per-subject bias estimation using fixed global slope\n",
    "for subject, group in sample.groupby(\"subject\"):\n",
    "    # process each split separately, because slope depends on split\n",
    "    for split_name in [\"train\", \"test\"]:\n",
    "        sub = group[group[\"split\"] == split_name]\n",
    "        if sub.empty: continue  # this subject has no samples in this split\n",
    "        # use global slopes\n",
    "        a_min = global_slopes[(split_name, \"min\")]\n",
    "        a_max = global_slopes[(split_name, \"max\")]\n",
    "        # we use condition == 1 samples from this subject for bias estimation\n",
    "        calib = sub[sub[\"condition\"] == 1]\n",
    "        # MinBP: bias b_min_subject\n",
    "        if calib[\"PredMinBP\"].notna().sum() >= 1:\n",
    "            # (P-T)_i ≈ a_global * Pred_i + b_subject\n",
    "            # => b_subject = mean((P-T)_i - a_global * Pred_i)\n",
    "            b_min = np.nanmean(\n",
    "                calib[\"(P-T)MinBP\"] - a_min * calib[\"PredMinBP\"]\n",
    "            )\n",
    "        else:\n",
    "            b_min = 0.0  # no info, fallback to 0\n",
    "        # MaxBP: bias b_max_subject\n",
    "        if calib[\"PredMaxBP\"].notna().sum() >= 1:\n",
    "            b_max = np.nanmean(\n",
    "                calib[\"(P-T)MaxBP\"] - a_max * calib[\"PredMaxBP\"]\n",
    "            )\n",
    "        else:\n",
    "            b_max = 0.0\n",
    "        # apply calibration to all rows of this subject & split\n",
    "        idx = sub.index\n",
    "        pred_min = sample.loc[idx, \"PredMinBP\"]\n",
    "        pred_max = sample.loc[idx, \"PredMaxBP\"]\n",
    "        true_min = sample.loc[idx, \"TrueMinBP\"]\n",
    "        true_max = sample.loc[idx, \"TrueMaxBP\"]\n",
    "        # predicted error from fixed-slope + subject-specific bias\n",
    "        err_hat_min = a_min * pred_min + b_min\n",
    "        err_hat_max = a_max * pred_max + b_max\n",
    "        adj_pred_min = pred_min - err_hat_min\n",
    "        adj_pred_max = pred_max - err_hat_max\n",
    "        sample.loc[idx, \"Cal2PredMinBP\"]  = adj_pred_min\n",
    "        sample.loc[idx, \"Cal2PredMaxBP\"]  = adj_pred_max\n",
    "        sample.loc[idx, \"(Cal2P-T)MinBP\"] = adj_pred_min - true_min\n",
    "        sample.loc[idx, \"(Cal2P-T)MaxBP\"] = adj_pred_max - true_max\n",
    "# 2.3 print\n",
    "print(\"calibration 2\")\n",
    "for s in [\"train\", \"test\"]: print(\n",
    "    s, \"\\tMAE of (min, max) = ({:5.2f}, {:5.2f})\".format(\n",
    "        np.nanmean(np.abs(\n",
    "            sample[\n",
    "                (sample[\"split\"] == s) & (sample[\"condition\"] != 1)\n",
    "            ][\"(Cal2P-T)MinBP\"]\n",
    "        )),\n",
    "        np.nanmean(np.abs(\n",
    "            sample[\n",
    "                (sample[\"split\"] == s) & (sample[\"condition\"] != 1)\n",
    "            ][\"(Cal2P-T)MaxBP\"]\n",
    "        )),\n",
    "    )\n",
    ")\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacbf3e-f8b1-435c-bb77-992873a02dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d372a0c7f44da6a3d98d316f15c95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='x1', index=2, layout=Layout(width='220px'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" visualization \"\"\"\n",
    "\n",
    "# ========== Global constants / config ==========\n",
    "COMMON_FONT = 12\n",
    "BOOL_STR_MAP = {\n",
    "    False: \"false\", True: \"true\",\n",
    "    \"False\": \"false\", \"True\": \"true\",\n",
    "    0: \"false\", 1: \"true\"\n",
    "}\n",
    "COLOR_SEQ = plotly.express.colors.qualitative.Plotly\n",
    "SYMBOL_SEQ = [\"circle\", \"square\", \"diamond\", \"x\", \"cross\", \"triangle-up\"]\n",
    "\n",
    "# Columns used for filtering / hover\n",
    "filter_cols = [\"subject\", \"health\", \"system\", \"repeat\", \"condition\", \"split\",]\n",
    "hover_cols = [\"subject\", \"health\", \"system\", \"repeat\", \"condition\", \"split\",]\n",
    "multi_filter_cols = [\"subject\", \"condition\"]\n",
    "bool_like_cols   = [\"health\", \"system\", \"repeat\", \"split\"]\n",
    "\n",
    "def compute_waveform_ranges(waveforms: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute global y-range for the two waveform rows.\n",
    "\n",
    "    Args:\n",
    "        waveforms: \n",
    "            array of shape (N, 7, T) containing waveforms for all samples.\n",
    "\n",
    "    Returns:\n",
    "        wave_range_row1: \n",
    "            [ymin, ymax] for row 1 (channels 5-6, \"before normalization\")\n",
    "        wave_range_row2: \n",
    "            [ymin, ymax] for row 2 (channels 0-4, \"after normalization\")\n",
    "        N_T: number of time points\n",
    "        GLOBAL_T: shared time axis (0..T-1)\n",
    "    \"\"\"\n",
    "    # Top row: ch5–6 (BP before normalization)\n",
    "    wave_min_row1 = float(waveforms[:, 5:7, :].min())\n",
    "    wave_max_row1 = float(waveforms[:, 5:7, :].max())\n",
    "\n",
    "    # Bottom row: ch0–4 (after normalization)\n",
    "    wave_min_row2 = float(waveforms[:, 0:5, :].min())\n",
    "    wave_max_row2 = float(waveforms[:, 0:5, :].max())\n",
    "\n",
    "    # Add small padding so curves don't sit exactly at the border\n",
    "    pad1 = 0.05 * (wave_max_row1 - wave_min_row1 + 1e-8)\n",
    "    pad2 = 0.05 * (wave_max_row2 - wave_min_row2 + 1e-8)\n",
    "\n",
    "    wave_range_row1 = [wave_min_row1 - pad1, wave_max_row1 + pad1]\n",
    "    wave_range_row2 = [wave_min_row2 - pad2, wave_max_row2 + pad2]\n",
    "\n",
    "    N_T = waveforms.shape[2]\n",
    "    GLOBAL_T = np.arange(N_T)\n",
    "\n",
    "    return wave_range_row1, wave_range_row2, N_T, GLOBAL_T\n",
    "\n",
    "def create_controls(sample: pd.DataFrame, numeric_cols: list[str]):\n",
    "    \"\"\"\n",
    "    Create all interactive widgets (controls) for the dashboard.\n",
    "\n",
    "    Returns a dict containing:\n",
    "        - x1_dropdown, y1_dropdown, x2_dropdown, y2_dropdown\n",
    "        - color_dropdown, size_input, opacity_input\n",
    "        - multi_filter_widgets, bool_filter_radios\n",
    "        - widgets_list: flat list of widgets to bind update callbacks\n",
    "        - left_col: pre-assembled left column layout for UI\n",
    "    \"\"\"\n",
    "    UNIFIED_WIDTH = \"220px\"\n",
    "    CONTROL_STYLE = {\"description_width\": \"70px\"}\n",
    "\n",
    "    # ---- axes selection (x1, y1, x2, y2) ----\n",
    "    x1_dropdown = ipywidgets.Dropdown(\n",
    "        options=numeric_cols, value=\"PredMinBP\", description=\"x1\",\n",
    "        layout=ipywidgets.Layout(width=UNIFIED_WIDTH), style=CONTROL_STYLE,\n",
    "    )\n",
    "    y1_dropdown = ipywidgets.Dropdown(\n",
    "        options=numeric_cols, value=\"(P-T)MinBP\", description=\"y1\",\n",
    "        layout=ipywidgets.Layout(width=UNIFIED_WIDTH), style=CONTROL_STYLE,\n",
    "    )\n",
    "    x2_dropdown = ipywidgets.Dropdown(\n",
    "        options=[None] + numeric_cols, value=None, description=\"x2\",\n",
    "        layout=ipywidgets.Layout(width=UNIFIED_WIDTH), style=CONTROL_STYLE,\n",
    "    )\n",
    "    y2_dropdown = ipywidgets.Dropdown(\n",
    "        options=[None] + numeric_cols, value=None, description=\"y2\",\n",
    "        layout=ipywidgets.Layout(width=UNIFIED_WIDTH), style=CONTROL_STYLE,\n",
    "    )\n",
    "\n",
    "    # ---- color by categorical column ----\n",
    "    color_dropdown = ipywidgets.Dropdown(\n",
    "        options=filter_cols, value=\"condition\", description=\"color\",\n",
    "        layout=ipywidgets.Layout(width=UNIFIED_WIDTH), style=CONTROL_STYLE,\n",
    "    )\n",
    "\n",
    "    # ---- point size and opacity ----\n",
    "    size_input = ipywidgets.BoundedIntText(\n",
    "        value=4, min=1, max=15, step=1, description=\"size\",\n",
    "        layout=ipywidgets.Layout(width=UNIFIED_WIDTH), style=CONTROL_STYLE,\n",
    "    )\n",
    "    opacity_input = ipywidgets.BoundedFloatText(\n",
    "        value=0.7, min=0.1, max=1.0, step=0.05, description=\"opacity\",\n",
    "        layout=ipywidgets.Layout(width=UNIFIED_WIDTH), style=CONTROL_STYLE\n",
    "    )\n",
    "\n",
    "    # ---- multi-value filters (subject / condition) using SelectMultiple ----\n",
    "    multi_filter_widgets = {}\n",
    "    for col in multi_filter_cols:\n",
    "        unique_vals = sorted(sample[col].unique())\n",
    "        options = [(str(v), v) for v in unique_vals]\n",
    "        sm = ipywidgets.SelectMultiple(\n",
    "            options=options,\n",
    "            value=tuple(v for _, v in options),  # select all by default\n",
    "            description=col,\n",
    "            layout=ipywidgets.Layout(width=UNIFIED_WIDTH, height=\"125px\"),\n",
    "            style=CONTROL_STYLE,\n",
    "        )\n",
    "        multi_filter_widgets[col] = sm\n",
    "\n",
    "    # ---- boolean-like filters using Dropdown ----\n",
    "    bool_filter_radios = {}\n",
    "    for col in bool_like_cols:\n",
    "        unique_vals = sorted(sample[col].unique())\n",
    "        # For some columns we show lowercase Boolean labels\n",
    "        options = (\n",
    "            [(\"all\", \"__ALL__\")] + \n",
    "            [(str(v).lower(), v) for v in unique_vals]\n",
    "        ) if col in [\"health\", \"repeat\"] else (\n",
    "            [(\"all\", \"__ALL__\")] + [(str(v), v) for v in unique_vals]\n",
    "        )\n",
    "        radio = ipywidgets.Dropdown(\n",
    "            options=options,\n",
    "            value=\"test\" if col == \"split\" else \"__ALL__\",\n",
    "            description=col,\n",
    "            layout=ipywidgets.Layout(width=UNIFIED_WIDTH),\n",
    "            style=CONTROL_STYLE,\n",
    "        )\n",
    "        bool_filter_radios[col] = radio\n",
    "\n",
    "    # ========= Left-side UI layout (all controls in one HBox) =========\n",
    "    left_col = ipywidgets.HBox([\n",
    "        ipywidgets.VBox([\n",
    "            x1_dropdown, y1_dropdown,\n",
    "            x2_dropdown, y2_dropdown,\n",
    "        ]),\n",
    "        ipywidgets.VBox([\n",
    "            color_dropdown,\n",
    "            size_input,\n",
    "            opacity_input,\n",
    "        ]),\n",
    "        multi_filter_widgets[\"subject\"],\n",
    "        multi_filter_widgets[\"condition\"],\n",
    "        ipywidgets.VBox([\n",
    "            bool_filter_radios[\"health\"],\n",
    "            bool_filter_radios[\"system\"],\n",
    "            bool_filter_radios[\"repeat\"],\n",
    "            bool_filter_radios[\"split\"],\n",
    "        ]),\n",
    "    ])\n",
    "\n",
    "    # ========= Widgets list to attach the update callback =========\n",
    "    widgets_list = [\n",
    "        x1_dropdown, y1_dropdown,\n",
    "        x2_dropdown, y2_dropdown,\n",
    "        color_dropdown,\n",
    "    ] + list(\n",
    "        multi_filter_widgets.values()\n",
    "    ) + list(bool_filter_radios.values()) + [size_input, opacity_input]\n",
    "\n",
    "    return {\n",
    "        \"x1_dropdown\": x1_dropdown,\n",
    "        \"y1_dropdown\": y1_dropdown,\n",
    "        \"x2_dropdown\": x2_dropdown,\n",
    "        \"y2_dropdown\": y2_dropdown,\n",
    "        \"color_dropdown\": color_dropdown,\n",
    "        \"size_input\": size_input,\n",
    "        \"opacity_input\": opacity_input,\n",
    "        \"multi_filter_widgets\": multi_filter_widgets,\n",
    "        \"bool_filter_radios\": bool_filter_radios,\n",
    "        \"widgets_list\": widgets_list,\n",
    "        \"left_col\": left_col,\n",
    "    }\n",
    "\n",
    "def build_dashboard(sample: pd.DataFrame, result: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Build and display the full scatter + waveform dashboard.\n",
    "\n",
    "    Args:\n",
    "        sample: dataframe with metadata and numeric prediction/metric columns.\n",
    "        result: torch.Tensor of shape (N, 7, T) holding waveforms to visualize.\n",
    "\n",
    "    Returns:\n",
    "        The top-level ipywidgets container (VBox).\n",
    "    \"\"\"\n",
    "    # ------- Prepare waveform data and global ranges -------\n",
    "    waveforms = result.detach().cpu().numpy()  # (N, 7, 1000)\n",
    "    wave_range_row1, wave_range_row2, N_T, GLOBAL_T = (\n",
    "        compute_waveform_ranges(waveforms)\n",
    "    )\n",
    "\n",
    "    # Numeric columns for x/y axes selection\n",
    "    numeric_cols = sample.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    # Create all control widgets\n",
    "    controls = create_controls(sample, numeric_cols)\n",
    "    plot_output = ipywidgets.Output()\n",
    "\n",
    "    # Global state for update_plot (captured via nonlocal)\n",
    "    # prevents recursive updates when we modify widget options\n",
    "    suppress_update = False\n",
    "    # position of \"sample_idx\" inside customdata array\n",
    "    sample_idx_pos = None\n",
    "    # mapping from semantic name to trace index for waveform       \n",
    "    wave_trace_indices = {}\n",
    "\n",
    "    def update_plot(*args):\n",
    "        \"\"\"\n",
    "        Main callback to:\n",
    "          1) apply filters based on current widget values\n",
    "          2) build scatter + waveform subplots\n",
    "          3) wire up click callbacks to show waveform for a selected point\n",
    "        \"\"\"\n",
    "        nonlocal suppress_update, sample_idx_pos, wave_trace_indices\n",
    "        if suppress_update: return\n",
    "\n",
    "        with plot_output:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # Step 1: Apply boolean-like filters \n",
    "            df_bool = sample\n",
    "            for col, w in controls[\"bool_filter_radios\"].items():\n",
    "                val = w.value\n",
    "                if val == \"__ALL__\":\n",
    "                    continue\n",
    "                df_bool = df_bool[df_bool[col] == val]\n",
    "            if df_bool.empty:\n",
    "                # If no samples left, clear multi filters and bail out\n",
    "                suppress_update = True\n",
    "                try:\n",
    "                    for col, w in controls[\"multi_filter_widgets\"].items():\n",
    "                        w.options = []\n",
    "                        w.value = ()\n",
    "                finally:\n",
    "                    suppress_update = False\n",
    "                print(\"No samples match the current filters.\")\n",
    "                return\n",
    "\n",
    "            # Step 2: Update options for subject / condition based on df_bool \n",
    "            suppress_update = True\n",
    "            try:\n",
    "                for col, w in controls[\"multi_filter_widgets\"].items():\n",
    "                    new_vals = sorted(df_bool[col].unique())\n",
    "                    new_options = [(str(v), v) for v in new_vals]\n",
    "\n",
    "                    old_selected = list(w.value)\n",
    "                    new_selected = (\n",
    "                        tuple(v for v in old_selected if v in new_vals)\n",
    "                    )\n",
    "\n",
    "                    # If nothing from old selection is valid, fallback to all\n",
    "                    if len(new_selected) == 0:\n",
    "                        new_selected = tuple(new_vals)\n",
    "\n",
    "                    w.options = new_options\n",
    "                    w.value = new_selected\n",
    "            finally:\n",
    "                suppress_update = False\n",
    "\n",
    "            # Step 3: Apply multi-value filters (subject / condition) \n",
    "            sub_df = df_bool\n",
    "            for col, w in controls[\"multi_filter_widgets\"].items():\n",
    "                selected = list(w.value)\n",
    "                if len(selected) > 0: \n",
    "                    sub_df = sub_df[sub_df[col].isin(selected)]\n",
    "\n",
    "            if sub_df.empty:\n",
    "                print(\"No samples match the current filters.\")\n",
    "                return\n",
    "\n",
    "            # Add \"sample_idx\" representing row index in original `sample`\n",
    "            sub_df = sub_df.copy()\n",
    "            sub_df[\"sample_idx\"] = sub_df.index\n",
    "\n",
    "            # Step 4: Prepare data for scatter (pair1 / pair2) \n",
    "            x1 = controls[\"x1_dropdown\"].value\n",
    "            y1 = controls[\"y1_dropdown\"].value\n",
    "            x2 = controls[\"x2_dropdown\"].value\n",
    "            y2 = controls[\"y2_dropdown\"].value\n",
    "            has_x2 = (x2 is not None) and (y2 is not None)\n",
    "\n",
    "            color_col = controls[\"color_dropdown\"].value\n",
    "            point_size = controls[\"size_input\"].value\n",
    "            point_opacity = controls[\"opacity_input\"].value\n",
    "\n",
    "            df_list = []\n",
    "\n",
    "            # Pair 1\n",
    "            df1 = sub_df.copy()\n",
    "            df1[\"_x\"] = df1[x1]\n",
    "            df1[\"_y\"] = df1[y1]\n",
    "            df1[\"_pair\"] = \"pair1\"\n",
    "            df_list.append(df1)\n",
    "\n",
    "            # Optional pair 2\n",
    "            if has_x2:\n",
    "                df2 = sub_df.copy()\n",
    "                df2[\"_x\"] = df2[x2]\n",
    "                df2[\"_y\"] = df2[y2]\n",
    "                df2[\"_pair\"] = \"pair2\"\n",
    "                df_list.append(df2)\n",
    "\n",
    "            df_long = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "            # --- Color mapping for scatter ---\n",
    "            if color_col:\n",
    "                df_long[\"_color_label\"] = (\n",
    "                    df_long[color_col]\n",
    "                    .map(BOOL_STR_MAP)\n",
    "                    .fillna(df_long[color_col])\n",
    "                    .astype(str)\n",
    "                ) if color_col in [\"health\", \"repeat\"] else (\n",
    "                    df_long[color_col].astype(str)\n",
    "                )\n",
    "                color_vals = sorted(df_long[\"_color_label\"].unique())\n",
    "            else:\n",
    "                df_long[\"_color_label\"] = \"all\"\n",
    "                color_vals = [\"all\"]\n",
    "            color_map = {\n",
    "                v: COLOR_SEQ[i % len(COLOR_SEQ)] \n",
    "                for i, v in enumerate(color_vals)\n",
    "            }\n",
    "\n",
    "            # --- Marker shape mapping for x1 vs y1 / x2 vs y2 ---\n",
    "            pair_vals = sorted(df_long[\"_pair\"].unique())\n",
    "            symbol_map = {p: SYMBOL_SEQ[i] for i, p in enumerate(pair_vals)}\n",
    "            if \"pair1\" not in symbol_map: symbol_map[\"pair1\"] = SYMBOL_SEQ[0]\n",
    "            if \"pair2\" not in symbol_map: symbol_map[\"pair2\"] = SYMBOL_SEQ[1]\n",
    "\n",
    "            pair_label_map = {\n",
    "                \"pair1\": \"x1 vs y1\",\n",
    "                \"pair2\": \"x2 vs y2\",\n",
    "            }\n",
    "\n",
    "            # ====== Build hovertemplate and customdata for scatter ======\n",
    "            sample_idx_series = df_long[\"sample_idx\"].astype(int)\n",
    "            sample_idx_arr = sample_idx_series.to_numpy()\n",
    "\n",
    "            sub_indexed = sub_df.set_index(\"sample_idx\")\n",
    "\n",
    "            # Real x1/y1 values (not the _x/_y used for pair stacking)\n",
    "            x1_for_row = sub_indexed.loc[sample_idx_arr, x1].to_numpy()\n",
    "            y1_for_row = sub_indexed.loc[sample_idx_arr, y1].to_numpy()\n",
    "\n",
    "            custom_columns = []\n",
    "            lines = []\n",
    "\n",
    "            # First entries in customdata: x1, y1\n",
    "            custom_columns.append(x1_for_row)\n",
    "            custom_columns.append(y1_for_row)\n",
    "            lines.append(\"x1 = %{customdata[0]}\")\n",
    "            lines.append(\"y1 = %{customdata[1]}\")\n",
    "            next_idx = 2\n",
    "\n",
    "            # x2, y2 if present\n",
    "            if has_x2:\n",
    "                x2_for_row = sub_indexed.loc[sample_idx_arr, x2].to_numpy()\n",
    "                y2_for_row = sub_indexed.loc[sample_idx_arr, y2].to_numpy()\n",
    "                custom_columns.append(x2_for_row)\n",
    "                custom_columns.append(y2_for_row)\n",
    "                lines.append(f\"x2 = %{{customdata[{next_idx}]}}\")\n",
    "                lines.append(f\"y2 = %{{customdata[{next_idx+1}]}}\")\n",
    "                next_idx += 2\n",
    "\n",
    "            # sample index \"s\"\n",
    "            sample_idx_pos = next_idx\n",
    "            custom_columns.append(sample_idx_arr)\n",
    "            lines.append(f\"s = %{{customdata[{next_idx}]}}\")\n",
    "            next_idx += 1\n",
    "\n",
    "            # metadata columns in hover\n",
    "            for col in hover_cols:\n",
    "                if col in [\"health\", \"repeat\"]:\n",
    "                    vals = (\n",
    "                        df_long[col]\n",
    "                        .map(BOOL_STR_MAP)\n",
    "                        .fillna(df_long[col])\n",
    "                        .astype(str)\n",
    "                        .to_numpy()\n",
    "                    )\n",
    "                else:\n",
    "                    vals = df_long[col].astype(str).to_numpy()\n",
    "                custom_columns.append(vals)\n",
    "                lines.append(f\"{col} = %{{customdata[{next_idx}]}}\")\n",
    "                next_idx += 1\n",
    "\n",
    "            hover_template = \"<br>\".join(lines) + \"<extra></extra>\"\n",
    "            customdata = np.column_stack(custom_columns)\n",
    "\n",
    "            # Build 2×2 subplot layout: \n",
    "            # left scatter, right-top/right-bottom waveform\n",
    "            base_fig = plotly.subplots.make_subplots(\n",
    "                rows=2, cols=2,\n",
    "                specs=[\n",
    "                    [{\"rowspan\": 2}, {\"type\": \"xy\"}],\n",
    "                    [None, {\"type\": \"xy\"}]\n",
    "                ],\n",
    "                column_widths=[0.5, 0.5],\n",
    "                row_heights=[0.5, 0.5],\n",
    "                horizontal_spacing=0.035,\n",
    "                vertical_spacing=0.035,\n",
    "                # share x-axis for right-top and right-bottom waveform plots\n",
    "                shared_xaxes=True,   \n",
    "            )\n",
    "            fig = plotly.graph_objects.FigureWidget(base_fig)\n",
    "\n",
    "            # --- Scatter traces (main data) ---\n",
    "            if color_col:\n",
    "                for c in color_vals:\n",
    "                    for p in pair_vals:\n",
    "                        mask = (\n",
    "                            (df_long[\"_color_label\"] == c) & \n",
    "                            (df_long[\"_pair\"] == p)\n",
    "                        )\n",
    "                        if not mask.any():\n",
    "                            continue\n",
    "                        sub = df_long[mask]\n",
    "                        fig.add_trace(\n",
    "                            plotly.graph_objects.Scatter(\n",
    "                                x=sub[\"_x\"],\n",
    "                                y=sub[\"_y\"],\n",
    "                                mode=\"markers\",\n",
    "                                marker=dict(\n",
    "                                    color=color_map[c],\n",
    "                                    symbol=symbol_map.get(p, SYMBOL_SEQ[0]),\n",
    "                                    size=point_size,\n",
    "                                    opacity=point_opacity,\n",
    "                                ),\n",
    "                                customdata=customdata[mask.to_numpy()],\n",
    "                                hovertemplate=hover_template,\n",
    "                                showlegend=False,\n",
    "                            ),\n",
    "                            row=1, col=1,\n",
    "                        )\n",
    "            else:\n",
    "                # No color grouping: use a single color\n",
    "                for p in pair_vals:\n",
    "                    mask = (df_long[\"_pair\"] == p)\n",
    "                    if not mask.any():\n",
    "                        continue\n",
    "                    sub = df_long[mask]\n",
    "                    fig.add_trace(\n",
    "                        plotly.graph_objects.Scatter(\n",
    "                            x=sub[\"_x\"],\n",
    "                            y=sub[\"_y\"],\n",
    "                            mode=\"markers\",\n",
    "                            marker=dict(\n",
    "                                color=\"blue\",\n",
    "                                symbol=symbol_map.get(p, SYMBOL_SEQ[0]),\n",
    "                                size=point_size,\n",
    "                                opacity=point_opacity,\n",
    "                            ),\n",
    "                            customdata=customdata[mask.to_numpy()],\n",
    "                            hovertemplate=hover_template,\n",
    "                            showlegend=False,\n",
    "                        ),\n",
    "                        row=1, col=1,\n",
    "                    )\n",
    "\n",
    "            # ========= Placeholder waveform traces =========\n",
    "            t = GLOBAL_T\n",
    "            color_bp_true = \"#1f77b4\"\n",
    "            color_bp_pred = \"#ff7f0e\"\n",
    "\n",
    "            waveform_hover = (\n",
    "                \"T = %{x}<br>\"\n",
    "                \"BP True = %{customdata[0]:.2f}<br>\"\n",
    "                \"BP Pred = %{customdata[1]:.2f}<br>\"\n",
    "                \"|Pred-True| = %{customdata[2]:.2f}<extra></extra>\"\n",
    "            )\n",
    "\n",
    "            # Placeholder customdata for waveform (will be filled on click)\n",
    "            empty_wave_custom = np.zeros((N_T, 3), dtype=float)\n",
    "\n",
    "            # Row 1 right: BP True / BP Pred before normalization\n",
    "            start_idx = len(fig.data)\n",
    "            idx_bp_before_true = start_idx\n",
    "            fig.add_trace(\n",
    "                plotly.graph_objects.Scatter(\n",
    "                    x=t,\n",
    "                    y=np.full(N_T, np.nan),\n",
    "                    mode=\"lines\",\n",
    "                    name=\"BP True\",\n",
    "                    line=dict(color=color_bp_true, width=2),\n",
    "                    legendgroup=\"waveform\",\n",
    "                    legendgrouptitle_text=\"waveform\",\n",
    "                    showlegend=True,\n",
    "                    customdata=empty_wave_custom,\n",
    "                    hovertemplate=waveform_hover,\n",
    "                ),\n",
    "                row=1, col=2,\n",
    "            )\n",
    "            idx_bp_before_pred = start_idx + 1\n",
    "            fig.add_trace(\n",
    "                plotly.graph_objects.Scatter(\n",
    "                    x=t,\n",
    "                    y=np.full(N_T, np.nan),\n",
    "                    mode=\"lines\",\n",
    "                    name=\"BP Pred\",\n",
    "                    line=dict(color=color_bp_pred, width=2),\n",
    "                    legendgroup=\"waveform\",\n",
    "                    showlegend=True,\n",
    "                    customdata=empty_wave_custom,\n",
    "                    hovertemplate=waveform_hover,\n",
    "                ),\n",
    "                row=1, col=2,\n",
    "            )\n",
    "\n",
    "            # Row 2 right: ch0-2 + BP True/Pred after normalization\n",
    "            idx_ch0 = len(fig.data)\n",
    "            for ch in range(3):\n",
    "                fig.add_trace(\n",
    "                    plotly.graph_objects.Scatter(\n",
    "                        x=t,\n",
    "                        y=np.full(N_T, np.nan),\n",
    "                        mode=\"lines\",\n",
    "                        name=f\"ch{ch}\",\n",
    "                        opacity=0.5,\n",
    "                        line=dict(width=2.0),\n",
    "                        legendgroup=\"waveform\",\n",
    "                        showlegend=True,\n",
    "                    ),\n",
    "                    row=2, col=2,\n",
    "                )\n",
    "            idx_bp_after_true = idx_ch0 + 3\n",
    "            fig.add_trace(\n",
    "                plotly.graph_objects.Scatter(\n",
    "                    x=t,\n",
    "                    y=np.full(N_T, np.nan),\n",
    "                    mode=\"lines\",\n",
    "                    name=\"BP True\",\n",
    "                    line=dict(color=color_bp_true, width=2),\n",
    "                    legendgroup=\"waveform\",\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=2, col=2,\n",
    "            )\n",
    "            idx_bp_after_pred = idx_ch0 + 4\n",
    "            fig.add_trace(\n",
    "                plotly.graph_objects.Scatter(\n",
    "                    x=t,\n",
    "                    y=np.full(N_T, np.nan),\n",
    "                    mode=\"lines\",\n",
    "                    name=\"BP Pred\",\n",
    "                    line=dict(color=color_bp_pred, width=2),\n",
    "                    legendgroup=\"waveform\",\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=2, col=2,\n",
    "            )\n",
    "\n",
    "            # Map human-readable names to trace indices for later updates\n",
    "            wave_trace_indices = {\n",
    "                \"bp_before_true\": idx_bp_before_true,\n",
    "                \"bp_before_pred\": idx_bp_before_pred,\n",
    "                \"ch0\": idx_ch0,\n",
    "                \"ch1\": idx_ch0 + 1,\n",
    "                \"ch2\": idx_ch0 + 2,\n",
    "                \"bp_after_true\": idx_bp_after_true,\n",
    "                \"bp_after_pred\": idx_bp_after_pred,\n",
    "            }\n",
    "\n",
    "            # Scatter legend: first shapes (pair1 vs pair2), then colors\n",
    "            # Shape legend entries (x1 vs y1 / x2 vs y2)\n",
    "            for i, p in enumerate([\"pair1\", \"pair2\"]):\n",
    "                fig.add_trace(\n",
    "                    plotly.graph_objects.Scatter(\n",
    "                        x=[None], y=[None],\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(\n",
    "                            color=\"black\",\n",
    "                            size=COMMON_FONT,\n",
    "                            symbol=symbol_map.get(p, SYMBOL_SEQ[i]),\n",
    "                        ),\n",
    "                        name=pair_label_map[p],\n",
    "                        showlegend=True,\n",
    "                        legendgroup=\"scatter\",\n",
    "                        legendgrouptitle_text=\"scatter\" if i == 0 else None,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Color legend entries\n",
    "            for c in color_vals:\n",
    "                fig.add_trace(\n",
    "                    plotly.graph_objects.Scatter(\n",
    "                        x=[None], y=[None],\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(\n",
    "                            color=color_map[c],\n",
    "                            size=COMMON_FONT,\n",
    "                        ),\n",
    "                        name=f\"{color_col} = {c}\",\n",
    "                        showlegend=True,\n",
    "                        legendgroup=\"scatter\",\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # ========= Axes ranges & layout =========\n",
    "            fig.update_yaxes(row=1, col=2, range=wave_range_row1)\n",
    "            fig.update_yaxes(row=2, col=2, range=wave_range_row2)\n",
    "\n",
    "            fig.update_xaxes(\n",
    "                showticklabels=False,\n",
    "                row=1, col=2,\n",
    "            )\n",
    "            fig.update_xaxes(row=2, col=2)\n",
    "\n",
    "            fig.update_layout(\n",
    "                height=520,\n",
    "                width=1200,\n",
    "                font=dict(size=COMMON_FONT),\n",
    "                margin=dict(l=0, r=0, t=0, b=0),\n",
    "                legend=dict(orientation=\"v\"),\n",
    "            )\n",
    "\n",
    "            # Click callback: update waveform by clicked scatter point\n",
    "            def handle_click(trace, points, state_click):\n",
    "                \"\"\"\n",
    "                On clicking a scatter point, look up the corresponding\n",
    "                waveform index and update all waveform traces accordingly.\n",
    "                \"\"\"\n",
    "                if not points.point_inds: return\n",
    "                idx0 = points.point_inds[0]\n",
    "                cd_row = trace.customdata[idx0]\n",
    "                s_idx = int(cd_row[sample_idx_pos])\n",
    "                if (s_idx < 0) or (s_idx >= waveforms.shape[0]): return\n",
    "\n",
    "                w = waveforms[s_idx]\n",
    "                # Expect (7, T): 5 channels + 2 BP waveforms\n",
    "                if (w.ndim != 2) or (w.shape[0] < 7): return\n",
    "\n",
    "                bp_true = w[5]\n",
    "                bp_pred = w[6]\n",
    "                bp_diff = np.abs(bp_true - bp_pred)\n",
    "\n",
    "                # Global MAE for min/max, shown in annotation\n",
    "                TrueMaxBP = float(bp_true.max())\n",
    "                PredMaxBP = float(bp_pred.max())\n",
    "                TrueMinBP = float(bp_true.min())\n",
    "                PredMinBP = float(bp_pred.min())\n",
    "                mae_max = abs(TrueMaxBP - PredMaxBP)\n",
    "                mae_min = abs(TrueMinBP - PredMinBP)\n",
    "\n",
    "                # Per-timepoint customdata for waveform hover: \n",
    "                # [true, pred, |pred-true|]\n",
    "                wave_custom = np.stack([bp_true, bp_pred, bp_diff], axis=1)\n",
    "\n",
    "                with fig.batch_update():\n",
    "                    # Update before-normalization traces\n",
    "                    fig.data[wave_trace_indices[\"bp_before_true\"]].y = bp_true\n",
    "                    fig.data[wave_trace_indices[\"bp_before_pred\"]].y = bp_pred\n",
    "\n",
    "                    fig.data[\n",
    "                        wave_trace_indices[\"bp_before_true\"]\n",
    "                    ].customdata = wave_custom\n",
    "                    fig.data[\n",
    "                        wave_trace_indices[\"bp_before_pred\"]\n",
    "                    ].customdata = wave_custom\n",
    "\n",
    "                    # Update after-normalization traces: ch0-2 + BP True/Pred\n",
    "                    fig.data[wave_trace_indices[\"ch0\"]].y = w[0]\n",
    "                    fig.data[wave_trace_indices[\"ch1\"]].y = w[1]\n",
    "                    fig.data[wave_trace_indices[\"ch2\"]].y = w[2]\n",
    "                    fig.data[wave_trace_indices[\"bp_after_true\"]].y = w[3]\n",
    "                    fig.data[wave_trace_indices[\"bp_after_pred\"]].y = w[4]\n",
    "\n",
    "                    # Annotation in the top-right waveform subplot\n",
    "                    fig.update_layout(annotations=[dict(\n",
    "                        xref=\"x2 domain\",\n",
    "                        yref=\"y2 domain\",\n",
    "                        x=1.0,\n",
    "                        y=0.0,\n",
    "                        text=(\n",
    "                            \"MAE of (min, max) = \" +\n",
    "                            f\"({mae_min:.2f}, {mae_max:.2f})\"\n",
    "                        ),\n",
    "                        showarrow=False,\n",
    "                        bgcolor=\"rgba(255,255,255,0.7)\",\n",
    "                        borderwidth=1,\n",
    "                        font=dict(size=COMMON_FONT),\n",
    "                    )])\n",
    "\n",
    "            # Attach click handler only to scatter traces with customdata\n",
    "            for tr in fig.data:\n",
    "                if (\n",
    "                    getattr(tr, \"mode\", None) == \"markers\"\n",
    "                    and getattr(tr, \"customdata\", None) is not None\n",
    "                ): tr.on_click(handle_click)\n",
    "\n",
    "            display(fig)\n",
    "\n",
    "    # ========= Bind events to update_plot =========\n",
    "    for w in controls[\"widgets_list\"]: w.observe(update_plot, names=\"value\")\n",
    "\n",
    "    # Top-level UI: controls on top, plot below\n",
    "    ui = ipywidgets.VBox([controls[\"left_col\"], plot_output])\n",
    "    display(ui)\n",
    "    update_plot()\n",
    "    return ui\n",
    "\n",
    "ui = build_dashboard(sample, result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
