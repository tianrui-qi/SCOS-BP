{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3b972d",
   "metadata": {},
   "source": [
    "## Finetune\n",
    "\n",
    "In `analysis.py`, I implemented subject-level adaptation. The workflow is to\n",
    "finetune on data from condition 1, and then test on data from the other\n",
    "conditions.\n",
    "\n",
    "There are several parameters involved:\n",
    "\n",
    "subject = \"S001\"\n",
    "config.runner.weight_min = 0.5\n",
    "config.runner.weight_max = 0.5\n",
    "\n",
    "Here, `subject` indicates which subject we want to finetune on.\n",
    "`weight_min` and `weight_max` control the contribution of different targets\n",
    "to the loss during training.\n",
    "\n",
    "Now, could you help me write a new script that extends this analysis to all\n",
    "subjects? Specifically, for each subject:\n",
    "\n",
    "- Use the following 5 parameter settings to finetune:\n",
    "  - `weight_min = [1e-6, 0.1, 0.5, 0.9, 1-1e-6]`\n",
    "  - `weight_max = [1-1e-6, 0.9, 0.5, 0.1, 1e-6]`\n",
    "  Each pair `(weight_min, weight_max)` defines one finetuning run, so we will\n",
    "  obtain 5 models per subject.\n",
    "- Use each model to predict data from this subject with `condition != 1`.\n",
    "  This yields 5 sets of `(PredMinBP, PredMaxBP)`, together with the ground\n",
    "  truth `(TrueMinBP, TrueMaxBP)`. Therefore, for each subject we will have\n",
    "  6 sets of values, i.e. 12 columns in total.\n",
    "- Repeat this procedure for every subject. Note that each subject is trained\n",
    "  independently: for each subject and each parameter setting, the checkpoint\n",
    "  must be reloaded and finetuning must be performed from scratch.\n",
    "\n",
    "In addition, although I say “all subjects,” we only need to process subjects\n",
    "with `split = 1` or `split = 2`. The `profile` file contains a column `split`.\n",
    "Although `split` is assigned at the sample level, in practice all samples of\n",
    "the same subject belong to the same split. I only care about subjects whose\n",
    "split is 1 or 2.\n",
    "\n",
    "After processing all subjects with split equal to 1 or 2, we will obtain a\n",
    "profile file of shape `N × (K + 2 × 6)`, where `K` is the number of original\n",
    "columns in `data.profile.copy()` (i.e., subject-level metadata).\n",
    "\n",
    "If a subject does not have data with `condition = 1`, or does not have any\n",
    "data with `condition != 1`, then skip this subject entirely. The final profile\n",
    "file should not include samples from this subject.\n",
    "\n",
    "Please save the final profile file to the directory\n",
    "`data/presentation/ResultFintune` (create this directory if it does not\n",
    "exist).\n",
    "\n",
    "If possible, please write this script as `script/temp.py`. I will run this\n",
    "file myself. When running, the script should display three nested `tqdm`\n",
    "progress bars:\n",
    "- The outer bar shows progress over subjects.\n",
    "- The middle bar shows progress over parameter settings for the current\n",
    "  subject.\n",
    "- The inner bar shows training progress for the current finetuning run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ebc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import src\n",
    "import config\n",
    "\n",
    "# Which config to use\n",
    "config_name = \"Finetune\"\n",
    "\n",
    "\n",
    "def _device() -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "def _set_seed_and_precision() -> None:\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "    lightning.seed_everything(42, workers=True, verbose=False)\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*MPS.*fallback.*\")\n",
    "\n",
    "\n",
    "def _load_model(cfg: config.Config, device: str) -> src.Model:\n",
    "    if cfg.trainer.ckpt_load_path is None:\n",
    "        raise ValueError(\"config.trainer.ckpt_load_path must be set\")\n",
    "    model = src.Model(**vars(cfg.model))\n",
    "    src.Trainer.ckptLoader_(model, cfg.trainer.ckpt_load_path).to(device)\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def _loss_shape(x: torch.Tensor, y: torch.Tensor, cfg) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(  # (B,)\n",
    "        input=torch.stack([\n",
    "            torch.roll(x, shifts=s, dims=-1)\n",
    "            for s in range(-cfg.runner.K, cfg.runner.K + 1)\n",
    "        ], dim=1)[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        target=y.unsqueeze(1).expand(\n",
    "            (-1, 2 * cfg.runner.K + 1, -1)\n",
    "        )[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        reduction=\"none\",\n",
    "    ).mean(dim=-1).min(dim=-1).values.mean()\n",
    "\n",
    "\n",
    "def _loss_min(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.min(dim=-1).values, y.min(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _loss_max(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.max(dim=-1).values, y.max(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _weight_tag(w_min: float, w_max: float) -> str:\n",
    "    def fmt(v: float) -> str:\n",
    "        txt = f\"{v:.6f}\"\n",
    "        txt = txt.rstrip(\"0\").rstrip(\".\") if \".\" in txt else txt\n",
    "        return txt.replace(\".\", \"p\")\n",
    "\n",
    "    return f\"wmin{fmt(w_min)}_wmax{fmt(w_max)}\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    _set_seed_and_precision()\n",
    "    device = _device()\n",
    "\n",
    "    cfg: config.Config = getattr(cfg, config_name)()\n",
    "    data = src.DataModule(**vars(cfg.data))\n",
    "    data.setup()\n",
    "\n",
    "    profile = data.profile.copy()\n",
    "    split_mask = profile[\"split\"].isin([1, 2])\n",
    "    subjects = sorted(profile.loc[split_mask, \"subject\"].unique())\n",
    "\n",
    "    weight_pairs: list[tuple[float, float]] = [\n",
    "        (1e-6, 1 - 1e-6),\n",
    "        (0.1, 0.9),\n",
    "        (0.5, 0.5),\n",
    "        (0.9, 0.1),\n",
    "        (1 - 1e-6, 1e-6),\n",
    "    ]\n",
    "\n",
    "    out_rows: list[pd.DataFrame] = []\n",
    "    subjects_bar = tqdm.tqdm(subjects, desc=\"Subjects\", position=0)\n",
    "    for subject in subjects_bar:\n",
    "        subjects_bar.set_postfix_str(subject)\n",
    "        subject_profile = profile.loc[profile[\"subject\"] == subject]\n",
    "        cond_eq1_mask = subject_profile[\"condition\"] == 1\n",
    "        cond_ne1_mask = subject_profile[\"condition\"] != 1\n",
    "        if (not cond_eq1_mask.any()) or (not cond_ne1_mask.any()):\n",
    "            subjects_bar.write(\n",
    "                f\"Skip {subject}: missing condition 1 or condition != 1 data\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        base_out = subject_profile.loc[cond_ne1_mask].copy().reset_index(drop=True)\n",
    "        true_filled = False\n",
    "\n",
    "        weight_bar = tqdm.tqdm(\n",
    "            weight_pairs, desc=\"Weight sets\", position=1, leave=False\n",
    "        )\n",
    "        for w_min, w_max in weight_bar:\n",
    "            weight_bar.set_postfix({\"w_min\": w_min, \"w_max\": w_max})\n",
    "            cfg.objective.weight_min = w_min\n",
    "            cfg.objective.weight_max = w_max\n",
    "\n",
    "            model = _load_model(cfg, device)\n",
    "\n",
    "            # backbone outputs for finetuning\n",
    "            x_train, y_train = [], []\n",
    "            for batch in data.train_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_train.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_train.append(batch[2])\n",
    "            x_train = torch.cat(x_train, dim=0)\n",
    "            y_train = torch.cat(y_train, dim=0)\n",
    "\n",
    "            x_valid, y_valid = [], []\n",
    "            for batch in data.val_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_valid.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_valid.append(batch[2])\n",
    "            x_valid = torch.cat(x_valid, dim=0)\n",
    "            y_valid = torch.cat(y_valid, dim=0)\n",
    "\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.objective.lr)\n",
    "\n",
    "            epoch_bar = tqdm.trange(\n",
    "                cfg.trainer.max_epochs, desc=\"Epochs\", position=2, leave=False\n",
    "            )\n",
    "            for _ in epoch_bar:\n",
    "                model.train()\n",
    "                x = model.forwardAdapter(x_train)\n",
    "                train_loss_shape = _loss_shape(x, y_train, cfg)\n",
    "                train_loss_min = _loss_min(x, y_train)\n",
    "                train_loss_max = _loss_max(x, y_train)\n",
    "                train_loss = (\n",
    "                    cfg.objective.weight_shape * train_loss_shape\n",
    "                    + cfg.objective.weight_min * train_loss_min\n",
    "                    + cfg.objective.weight_max * train_loss_max\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    x_val = model.forwardAdapter(x_valid)\n",
    "                    valid_loss_shape = _loss_shape(x_val, y_valid, cfg)\n",
    "                    valid_loss_min = _loss_min(x_val, y_valid)\n",
    "                    valid_loss_max = _loss_max(x_val, y_valid)\n",
    "                    valid_loss = (\n",
    "                        cfg.objective.weight_shape * valid_loss_shape\n",
    "                        + cfg.objective.weight_min * valid_loss_min\n",
    "                        + cfg.objective.weight_max * valid_loss_max\n",
    "                    )\n",
    "                epoch_bar.set_postfix(\n",
    "                    {\n",
    "                        \"train\": float(train_loss),\n",
    "                        \"valid\": float(valid_loss),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # prediction on this subject (all conditions), then keep condition != 1\n",
    "            model.eval()\n",
    "            result_batches = []\n",
    "            for batch in data.test_dataloader(subject=subject):\n",
    "                x, channel_idx, y = batch\n",
    "                x, channel_idx, y = x.to(device), channel_idx.to(device), y.to(device)\n",
    "                with torch.no_grad():\n",
    "                    x_pred = model.forwardRegression(\n",
    "                        x, channel_idx, adapter=True\n",
    "                    )\n",
    "                result_batches.append(torch.cat([\n",
    "                    x.detach().cpu(),                       # (B, 4, T)\n",
    "                    y.detach().cpu().unsqueeze(1),          # (B, 1, T)\n",
    "                    x_pred.detach().cpu().unsqueeze(1),     # (B, 1, T)\n",
    "                ], dim=1))\n",
    "            result = torch.cat(result_batches, dim=0)       # (N, 5, T)\n",
    "            result = torch.cat([\n",
    "                result,\n",
    "                data.denormalize(result[:, 3, :]).unsqueeze(1),\n",
    "                data.denormalize(result[:, 4, :]).unsqueeze(1),\n",
    "            ], dim=1).detach().cpu()                        # (N, 7, T)\n",
    "\n",
    "            true_min = result[:, 5].min(dim=1).values.numpy()\n",
    "            true_max = result[:, 5].max(dim=1).values.numpy()\n",
    "            pred_min = result[:, 6].min(dim=1).values.numpy()\n",
    "            pred_max = result[:, 6].max(dim=1).values.numpy()\n",
    "\n",
    "            cond_ne1_array = cond_ne1_mask.to_numpy()\n",
    "            if not true_filled:\n",
    "                base_out[\"TrueMinBP\"] = true_min[cond_ne1_array]\n",
    "                base_out[\"TrueMaxBP\"] = true_max[cond_ne1_array]\n",
    "                true_filled = True\n",
    "\n",
    "            tag = _weight_tag(w_min, w_max)\n",
    "            base_out[f\"PredMinBP_{tag}\"] = pred_min[cond_ne1_array]\n",
    "            base_out[f\"PredMaxBP_{tag}\"] = pred_max[cond_ne1_array]\n",
    "\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        out_rows.append(base_out)\n",
    "\n",
    "    if not out_rows:\n",
    "        print(\"No subjects processed; nothing saved.\")\n",
    "        return\n",
    "\n",
    "    out_df = pd.concat(out_rows, axis=0).reset_index(drop=True)\n",
    "    out_dir = Path(\"data/presentation/ResultFintune\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / \"profile.csv\"\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved aggregated profile to {out_path} (rows={len(out_df)})\")\n",
    "\n",
    "# Ensure the working directory is the repo root so relative paths resolve\n",
    "os.chdir(Path(__file__).resolve().parents[1])\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "While the code is running, please help me write a script to analyze this `profile`.\n",
    "\n",
    "I am very interested in the final overall MAE. There are two evaluation strategies.\n",
    "\n",
    "### Strategy 1: Single parameter set for all samples\n",
    "In the first strategy, all samples use the same parameter set to compute the final MAE.  \n",
    "Note that **min and max are treated separately**:  \n",
    "- one parameter set is chosen to minimize the MAE of **min**,  \n",
    "- another (possibly different) parameter set is chosen to minimize the MAE of **max**.  \n",
    "\n",
    "The requirement is that, within each case (min or max), the **same parameter set is applied to all subjects and all samples**.\n",
    "\n",
    "Please report:\n",
    "- which parameter set achieves the best MAE for **min**, and what that best MAE is;\n",
    "- which parameter set achieves the best MAE for **max**, and what that best MAE is.\n",
    "\n",
    "Then, please visualize:\n",
    "- the **per-subject MAE**;\n",
    "- all samples plotted together, with the x-axis being the prediction and the y-axis being the ground truth, colored by subject.\n",
    "\n",
    "---\n",
    "\n",
    "### Strategy 2: Best parameter set per subject\n",
    "In the second strategy, for each subject, the prediction values for **min** and **max** are taken from the parameter set that performs best for that subject.\n",
    "\n",
    "The remaining analysis is the same as in Strategy 1. Please also:\n",
    "- report the best overall MAE;\n",
    "- visualize the per-subject MAE;\n",
    "- visualize all samples plotted together, with the x-axis being the predicted BP and the y-axis being the ground truth, colored by subject.\n",
    "\n",
    "Note that in the visualizations, **min and max should be handled and plotted separately**.\n",
    "\n",
    "---\n",
    "\n",
    "Please write everything in `script/temp.ipynb` so that I can easily inspect all figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import dataclasses\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import src\n",
    "\n",
    "# Which config to use\n",
    "config_name = \"Finetune\"\n",
    "\n",
    "\n",
    "def _device() -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "def _set_seed_and_precision() -> None:\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "    lightning.seed_everything(42, workers=True, verbose=False)\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*MPS.*fallback.*\")\n",
    "\n",
    "\n",
    "def _load_model(cfg: config.Config, device: str) -> src.Model:\n",
    "    if cfg.trainer.ckpt_load_path is None:\n",
    "        raise ValueError(\"config.trainer.ckpt_load_path must be set\")\n",
    "    model = src.Model(**vars(cfg.model))\n",
    "    src.Trainer.ckptLoader_(model, cfg.trainer.ckpt_load_path).to(device)\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def _loss_shape(x: torch.Tensor, y: torch.Tensor, cfg) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(  # (B,)\n",
    "        input=torch.stack([\n",
    "            torch.roll(x, shifts=s, dims=-1)\n",
    "            for s in range(-cfg.runner.K, cfg.runner.K + 1)\n",
    "        ], dim=1)[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        target=y.unsqueeze(1).expand(\n",
    "            (-1, 2 * cfg.runner.K + 1, -1)\n",
    "        )[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        reduction=\"none\",\n",
    "    ).mean(dim=-1).min(dim=-1).values.mean()\n",
    "\n",
    "\n",
    "def _loss_min(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.min(dim=-1).values, y.min(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _loss_max(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.max(dim=-1).values, y.max(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _weight_tag(w_min: float, w_max: float) -> str:\n",
    "    def fmt(v: float) -> str:\n",
    "        txt = f\"{v:.6f}\"\n",
    "        txt = txt.rstrip(\"0\").rstrip(\".\") if \".\" in txt else txt\n",
    "        return txt.replace(\".\", \"p\")\n",
    "\n",
    "    return f\"wmin{fmt(w_min)}_wmax{fmt(w_max)}\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    _set_seed_and_precision()\n",
    "    device = _device()\n",
    "\n",
    "    config: src.config.Config = getattr(src.config, config_name)()\n",
    "    data = src.data.DataModule(**vars(config.data))\n",
    "    data.setup()\n",
    "\n",
    "    profile = data.profile.copy()\n",
    "    split_mask = profile[\"split\"].isin([1, 2])\n",
    "    subjects = sorted(profile.loc[split_mask, \"subject\"].unique())\n",
    "\n",
    "    weight_pairs: list[tuple[float, float]] = [\n",
    "        (1e-6, 1 - 1e-6),\n",
    "        (0.1, 0.9),\n",
    "        (0.5, 0.5),\n",
    "        (0.9, 0.1),\n",
    "        (1 - 1e-6, 1e-6),\n",
    "    ]\n",
    "\n",
    "    out_rows: list[pd.DataFrame] = []\n",
    "    subjects_bar = tqdm.tqdm(subjects, desc=\"Subjects\", position=0)\n",
    "    for subject in subjects_bar:\n",
    "        subjects_bar.set_postfix_str(subject)\n",
    "        subject_profile = profile.loc[profile[\"subject\"] == subject]\n",
    "        cond_eq1_mask = subject_profile[\"condition\"] == 1\n",
    "        cond_ne1_mask = subject_profile[\"condition\"] != 1\n",
    "        if (not cond_eq1_mask.any()) or (not cond_ne1_mask.any()):\n",
    "            subjects_bar.write(\n",
    "                f\"Skip {subject}: missing condition 1 or condition != 1 data\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        base_out = subject_profile.loc[cond_ne1_mask].copy().reset_index(drop=True)\n",
    "        true_filled = False\n",
    "\n",
    "        weight_bar = tqdm.tqdm(\n",
    "            weight_pairs, desc=\"Weight sets\", position=1, leave=False\n",
    "        )\n",
    "        for w_min, w_max in weight_bar:\n",
    "            weight_bar.set_postfix({\"w_min\": w_min, \"w_max\": w_max})\n",
    "            config.objective.weight_min = w_min\n",
    "            config.objective.weight_max = w_max\n",
    "\n",
    "            model = _load_model(config, device)\n",
    "\n",
    "            # backbone outputs for finetuning\n",
    "            x_train, y_train = [], []\n",
    "            for batch in data.train_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_train.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_train.append(batch[2])\n",
    "            x_train = torch.cat(x_train, dim=0)\n",
    "            y_train = torch.cat(y_train, dim=0)\n",
    "\n",
    "            x_valid, y_valid = [], []\n",
    "            for batch in data.val_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_valid.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_valid.append(batch[2])\n",
    "            x_valid = torch.cat(x_valid, dim=0)\n",
    "            y_valid = torch.cat(y_valid, dim=0)\n",
    "\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=config.objective.lr)\n",
    "\n",
    "            epoch_bar = tqdm.trange(\n",
    "                config.trainer.max_epochs, desc=\"Epochs\", position=2, leave=False\n",
    "            )\n",
    "            for _ in epoch_bar:\n",
    "                model.train()\n",
    "                x = model.forwardAdapter(x_train)\n",
    "                train_loss_shape = _loss_shape(x, y_train, config)\n",
    "                train_loss_min = _loss_min(x, y_train)\n",
    "                train_loss_max = _loss_max(x, y_train)\n",
    "                train_loss = (\n",
    "                    config.objective.weight_shape * train_loss_shape\n",
    "                    + config.objective.weight_min * train_loss_min\n",
    "                    + config.objective.weight_max * train_loss_max\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    x_val = model.forwardAdapter(x_valid)\n",
    "                    valid_loss_shape = _loss_shape(x_val, y_valid, config)\n",
    "                    valid_loss_min = _loss_min(x_val, y_valid)\n",
    "                    valid_loss_max = _loss_max(x_val, y_valid)\n",
    "                    valid_loss = (\n",
    "                        config.objective.weight_shape * valid_loss_shape\n",
    "                        + config.objective.weight_min * valid_loss_min\n",
    "                        + config.objective.weight_max * valid_loss_max\n",
    "                    )\n",
    "                epoch_bar.set_postfix(\n",
    "                    {\n",
    "                        \"train\": float(train_loss),\n",
    "                        \"valid\": float(valid_loss),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # prediction on this subject (all conditions), then keep condition != 1\n",
    "            model.eval()\n",
    "            result_batches = []\n",
    "            for batch in data.test_dataloader(subject=subject):\n",
    "                x, channel_idx, y = batch\n",
    "                x, channel_idx, y = x.to(device), channel_idx.to(device), y.to(device)\n",
    "                with torch.no_grad():\n",
    "                    x_pred = model.forwardRegressionAdapter(\n",
    "                        x, channel_idx\n",
    "                    )\n",
    "                result_batches.append(torch.cat([\n",
    "                    x.detach().cpu(),                       # (B, 4, T)\n",
    "                    y.detach().cpu().unsqueeze(1),          # (B, 1, T)\n",
    "                    x_pred.detach().cpu().unsqueeze(1),     # (B, 1, T)\n",
    "                ], dim=1))\n",
    "            result = torch.cat(result_batches, dim=0)       # (N, 5, T)\n",
    "            result = torch.cat([\n",
    "                result,\n",
    "                data.denormalize(result[:, 3, :]).unsqueeze(1),\n",
    "                data.denormalize(result[:, 4, :]).unsqueeze(1),\n",
    "            ], dim=1).detach().cpu()                        # (N, 7, T)\n",
    "\n",
    "            true_min = result[:, 5].min(dim=1).values.numpy()\n",
    "            true_max = result[:, 5].max(dim=1).values.numpy()\n",
    "            pred_min = result[:, 6].min(dim=1).values.numpy()\n",
    "            pred_max = result[:, 6].max(dim=1).values.numpy()\n",
    "\n",
    "            cond_ne1_array = cond_ne1_mask.to_numpy()\n",
    "            if not true_filled:\n",
    "                base_out[\"TrueMinBP\"] = true_min[cond_ne1_array]\n",
    "                base_out[\"TrueMaxBP\"] = true_max[cond_ne1_array]\n",
    "                true_filled = True\n",
    "\n",
    "            tag = _weight_tag(w_min, w_max)\n",
    "            base_out[f\"PredMinBP_{tag}\"] = pred_min[cond_ne1_array]\n",
    "            base_out[f\"PredMaxBP_{tag}\"] = pred_max[cond_ne1_array]\n",
    "\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        out_rows.append(base_out)\n",
    "\n",
    "    if not out_rows:\n",
    "        print(\"No subjects processed; nothing saved.\")\n",
    "        return\n",
    "\n",
    "    out_df = pd.concat(out_rows, axis=0).reset_index(drop=True)\n",
    "    out_dir = Path(\"data/presentation/ResultFintune\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / \"profile.csv\"\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved aggregated profile to {out_path} (rows={len(out_df)})\")\n",
    "\n",
    "\n",
    "# Ensure the working directory is the repo root so relative paths resolve\n",
    "os.chdir(Path(__file__).resolve().parents[1])\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "px.defaults.template = \"plotly_white\"\n",
    "px.defaults.width = 1250\n",
    "px.defaults.height = 600\n",
    "\n",
    "def mae(y_true, y_pred) -> float:\n",
    "    \"\"\"Nan-tolerant MAE.\"\"\"\n",
    "    diff = np.abs(np.asarray(y_true) - np.asarray(y_pred))\n",
    "    return float(np.nanmean(diff))\n",
    "\n",
    "output_dir = Path(\"data/presentation/ResultFintune\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path = output_dir / \"profile.csv\"\n",
    "profile = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect available parameter sets (tags)\n",
    "pred_min_cols = [c for c in profile.columns if c.startswith(\"PredMinBP_\")]\n",
    "pred_max_cols = [c for c in profile.columns if c.startswith(\"PredMaxBP_\")]\n",
    "tags_min = [c.removeprefix(\"PredMinBP_\") for c in pred_min_cols]\n",
    "tags_max = [c.removeprefix(\"PredMaxBP_\") for c in pred_max_cols]\n",
    "assert tags_min, \"No PredMinBP_* columns found\"\n",
    "assert tags_max, \"No PredMaxBP_* columns found\"\n",
    "tags_min, tags_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strategy 1: global best parameter set (separate best for min vs. max) ---\n",
    "def best_global(true_col: str, prefix: str, tags: list[str]):\n",
    "    scores = {\n",
    "        tag: mae(profile[true_col], profile[f\"{prefix}{tag}\"])\n",
    "        for tag in tags\n",
    "    }\n",
    "    best_tag = min(scores, key=scores.get)\n",
    "    return best_tag, scores\n",
    "\n",
    "best_min_tag, min_scores = best_global(\"TrueMinBP\", \"PredMinBP_\", tags_min)\n",
    "best_max_tag, max_scores = best_global(\"TrueMaxBP\", \"PredMaxBP_\", tags_max)\n",
    "best_min_mae = min_scores[best_min_tag]\n",
    "best_max_mae = max_scores[best_max_tag]\n",
    "\n",
    "metrics_text = (\n",
    "    f\"Global best (min): {best_min_tag} -> MAE = {best_min_mae:.4f}\\n\"\n",
    "    f\"Global best (max): {best_max_tag} -> MAE = {best_max_mae:.4f}\"\n",
    ")\n",
    "metrics_path = output_dir / \"01GlobalBestParas.txt\"\n",
    "metrics_path.write_text(metrics_text + \"\\n\")\n",
    "print(f\"Wrote global metrics to {metrics_path}\")\n",
    "\n",
    "# Per-sample errors for box plots\n",
    "err_rows = []\n",
    "for subj, df_sub in profile.groupby(\"subject\"):\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"diastolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMinBP\"] - df_sub[f\"PredMinBP_{best_min_tag}\"])\n",
    "    }))\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"systolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMaxBP\"] - df_sub[f\"PredMaxBP_{best_max_tag}\"])\n",
    "    }))\n",
    "sample_err_global = pd.concat(err_rows, ignore_index=True)\n",
    "\n",
    "fig_box_global = px.box(\n",
    "    sample_err_global, x=\"subject\", y=\"error\", color=\"metric\",\n",
    "    points=\"suspectedoutliers\", title=\"Per-sample error (global best tags)\",\n",
    "    labels={\"error\": \"|Pred-True|\", \"subject\": \"Subject\"}\n",
    ")\n",
    "\n",
    "fig_box_global.update_traces(marker=dict(size=3), whiskerwidth=0)\n",
    "fig_box_global.update_yaxes(type=\"log\", range=[0, 2])\n",
    "fig_box_global.write_image(output_dir / \"01GlobalBestParas.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994be8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strategy 2: per-subject best parameter set (separate for min vs. max) ---\n",
    "def best_tags_per_subject(true_col: str, prefix: str, tags: list[str]):\n",
    "    out = {}\n",
    "    for subj, df_sub in profile.groupby(\"subject\"):\n",
    "        scores = {\n",
    "            tag: mae(df_sub[true_col], df_sub[f\"{prefix}{tag}\"])\n",
    "            for tag in tags\n",
    "        }\n",
    "        out[subj] = min(scores, key=scores.get)\n",
    "    return out\n",
    "\n",
    "best_min_by_subj = best_tags_per_subject(\"TrueMinBP\", \"PredMinBP_\", tags_min)\n",
    "best_max_by_subj = best_tags_per_subject(\"TrueMaxBP\", \"PredMaxBP_\", tags_max)\n",
    "\n",
    "# Build columns with per-subject best predictions\n",
    "profile = profile.copy()\n",
    "profile[\"PredMinBP_best_subject\"] = np.nan\n",
    "profile[\"PredMaxBP_best_subject\"] = np.nan\n",
    "\n",
    "for subj, tag in best_min_by_subj.items():\n",
    "    mask = profile[\"subject\"] == subj\n",
    "    profile.loc[mask, \"PredMinBP_best_subject\"] = profile.loc[mask, f\"PredMinBP_{tag}\"]\n",
    "for subj, tag in best_max_by_subj.items():\n",
    "    mask = profile[\"subject\"] == subj\n",
    "    profile.loc[mask, \"PredMaxBP_best_subject\"] = profile.loc[mask, f\"PredMaxBP_{tag}\"]\n",
    "\n",
    "overall_min_mae = mae(profile[\"TrueMinBP\"], profile[\"PredMinBP_best_subject\"])\n",
    "overall_max_mae = mae(profile[\"TrueMaxBP\"], profile[\"PredMaxBP_best_subject\"])\n",
    "metrics_text = (\n",
    "    f\"Per-subject best (min): MAE = {overall_min_mae:.4f}\\n\"\n",
    "    f\"Per-subject best (max): MAE = {overall_max_mae:.4f}\"\n",
    ")\n",
    "metrics_path = output_dir / \"02SubjectBestParas.txt\"\n",
    "metrics_path.write_text(metrics_text + \"\\n\")\n",
    "print(f\"Wrote subject-level metrics to {metrics_path}\")\n",
    "\n",
    "# Per-sample errors for box plots (subject-specific best)\n",
    "err_rows = []\n",
    "for subj, df_sub in profile.groupby(\"subject\"):\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"diastolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMinBP\"] - df_sub[\"PredMinBP_best_subject\"]),\n",
    "    }))\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"systolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMaxBP\"] - df_sub[\"PredMaxBP_best_subject\"]),\n",
    "    }))\n",
    "sample_err_subject = pd.concat(err_rows, ignore_index=True)\n",
    "\n",
    "fig_box_subj = px.box(\n",
    "    sample_err_subject, x=\"subject\", y=\"error\", color=\"metric\",\n",
    "    points=\"suspectedoutliers\", title=\"Per-sample error (subject-specific best tags)\",\n",
    "    labels={\"error\": \"|Pred-True|\", \"subject\": \"Subject\"}\n",
    ")\n",
    "\n",
    "fig_box_subj.update_traces(marker=dict(size=3), whiskerwidth=0)\n",
    "fig_box_subj.update_yaxes(type=\"log\", range=[0, 2])\n",
    "fig_box_subj.write_image(output_dir / \"02SubjectBestParas.png\")\n",
    "\n",
    "# Quick look at which tag won per subject (optional table)\n",
    "pd.DataFrame({\n",
    "    \"subject\": list(best_min_by_subj.keys()),\n",
    "    \"best_min_tag\": list(best_min_by_subj.values()),\n",
    "    \"best_max_tag\": [best_max_by_subj[s] for s in best_min_by_subj.keys()],\n",
    "}).sort_values(\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: remove extreme errors (possible bad ground truth) and recompute\n",
    "pred_min_col = \"PredMinBP_best_subject\"\n",
    "pred_max_col = \"PredMaxBP_best_subject\"\n",
    "\n",
    "df_err = profile.copy()\n",
    "df_err[\"err_diastolic\"] = np.abs(df_err[\"TrueMinBP\"] - df_err[pred_min_col])\n",
    "df_err[\"err_systolic\"] = np.abs(df_err[\"TrueMaxBP\"] - df_err[pred_max_col])\n",
    "\n",
    "def filter_outliers_iqr(df: pd.DataFrame, cols: list[str], k: float = 1.5, max_pct: float = 0.99):\n",
    "    \"\"\"IQR + percentile cap: keep rows where each col <= min(q3 + k*IQR, pct(max_pct)).\"\"\"\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    thresholds: dict[str, float] = {}\n",
    "    for col in cols:\n",
    "        s = df[col].dropna()\n",
    "        if s.empty:\n",
    "            thresholds[col] = np.nan\n",
    "            continue\n",
    "        q1, q3 = s.quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        upper_iqr = q3 + k * iqr\n",
    "        upper_pct = s.quantile(max_pct)\n",
    "        upper = float(min(upper_iqr, upper_pct))\n",
    "        thresholds[col] = upper\n",
    "        mask &= df[col] <= upper\n",
    "    return df[mask].copy(), thresholds, mask\n",
    "\n",
    "filtered, thresholds, keep_mask = filter_outliers_iqr(\n",
    "    df_err, [\"err_diastolic\", \"err_systolic\"], k=1.5, max_pct=0.99\n",
    ")\n",
    "\n",
    "summary_lines = [\n",
    "    f\"Thresholds (abs error): {thresholds}\",\n",
    "    (\n",
    "        f\"Kept {len(filtered)} of {len(df_err)} samples (\"\n",
    "        f\"{keep_mask.mean()*100:.1f}%); removed {len(df_err) - len(filtered)}\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "filtered_min_mae = mae(filtered[\"TrueMinBP\"], filtered[pred_min_col])\n",
    "filtered_max_mae = mae(filtered[\"TrueMaxBP\"], filtered[pred_max_col])\n",
    "summary_lines.append(\n",
    "    \"Filtered overall MAE (diastolic, systolic): \"\n",
    "    f\"({filtered_min_mae:.4f}, {filtered_max_mae:.4f})\"\n",
    ")\n",
    "\n",
    "metrics_path = output_dir / \"03SubjectBestParasThresholds.txt\"\n",
    "metrics_path.write_text(\"\\n\".join(summary_lines) + \"\\n\")\n",
    "print(f\"Wrote filtered metrics to {metrics_path}\")\n",
    "\n",
    "# Box plot on filtered data (box + suspected outliers on same line)\n",
    "err_long = pd.concat([\n",
    "    filtered[[\"subject\", \"err_diastolic\"]].rename(columns={\"err_diastolic\": \"error\"}).assign(metric=\"diastolic\"),\n",
    "    filtered[[\"subject\", \"err_systolic\"]].rename(columns={\"err_systolic\": \"error\"}).assign(metric=\"systolic\"),\n",
    "])\n",
    "fig_box_filtered = px.box(\n",
    "    err_long, x=\"subject\", y=\"error\", color=\"metric\",\n",
    "    points=\"suspectedoutliers\",\n",
    "    title=\"Per-sample error after outlier removal (subject-specific best)\",\n",
    "    labels={\"error\": \"|Pred-True|\", \"subject\": \"Subject\"}\n",
    ")\n",
    "fig_box_filtered.update_traces(marker=dict(size=3), whiskerwidth=0)\n",
    "fig_box_filtered.update_yaxes(type=\"log\", range=[0, 2])\n",
    "fig_box_filtered.write_image(output_dir / \"03SubjectBestParasThresholds.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scos-bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
