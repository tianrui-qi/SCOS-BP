{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3b972d",
   "metadata": {},
   "source": [
    "## Finetune\n",
    "\n",
    "我analysis.py对脚本实现了对于一个subject的adaption。具体流程是finetune on condition 1的数据，然后test on 其他condition。\n",
    "\n",
    "这里面有一些参数\n",
    "\n",
    "subject = \"S001\"\n",
    "config.runner.weight_min = 0.5\n",
    "config.runner.weight_max = 0.5\n",
    "\n",
    "subject = 就是我们想finetune哪个subject。weight_min和weight_max决定了在train的时候不同值对loss的影响。\n",
    "\n",
    "现在，能不能帮我写个新的脚本，把这个analysis拓展到所有subject。具体来说，对于每个subject，\n",
    "- 用weight_min = 1e-6, 0.1, 0.5, 0.9, 1-1e-6, weight_min = 1-1e-6, 0.9, 0.5, 0.1, 1e-6, 这5种parameter来finetune，所以我们会得到5个model\n",
    "- 用每个model来predict这个subject的condition != 1的数据，那我们会得到5组（PredMinBP，PredMaxBP），加上（TrueMinBP，TrueMaxBP）的groud truth，对于每个subject我们就会有6组数，12个column\n",
    "对于每个subject，请重复这个操作。注意，每个subject是独立train的，需要每次都重新load ckpt然后finetune。每个subject的每个parameter组合也是独立train的。\n",
    "\n",
    "还有，注意虽然我说对所有subject做，但是其实只要对split=1或者2的subject来做就行，我的profile文件里有个column split。我只关心里面split=1或者2的subject。虽然这个split assign给了每个sample，但是其实是每个subject的所有sample都会被放进其中一个set。\n",
    "\n",
    "在对所有split属于1，2的subject都做完，我们会得到一个N*(K+2*6) 的profile文件，其中K是原本profile文件里data.profile.copy()的column，是每个subject的Metadata。\n",
    "\n",
    "如果有的subject没有condition=1的数据，或者没有condition！=1的数据，那就跳过这个subject，最终的profile文件里面也不用包含这个subject的samples。\n",
    "\n",
    "请把最终的这个profile文件保存到data/presentation/ResultFintune这个文件夹里，记得新建一下这个文件夹。\n",
    "\n",
    "如果可以，请把这个文件写在script/temp.py。我可以自己来跑这个文件。这个文件在跑的时候应该有三层tqdm bar，第一层展示目前subject进度，第二层展示这个subject进行到哪个parameters set了，第三层展示本次train的进度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ebc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import src\n",
    "import config\n",
    "\n",
    "# Which config to use\n",
    "config_name = \"Finetune\"\n",
    "\n",
    "\n",
    "def _device() -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "def _set_seed_and_precision() -> None:\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "    lightning.seed_everything(42, workers=True, verbose=False)\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*MPS.*fallback.*\")\n",
    "\n",
    "\n",
    "def _load_model(cfg: config.Config, device: str) -> src.Model:\n",
    "    if cfg.trainer.ckpt_load_path is None:\n",
    "        raise ValueError(\"config.trainer.ckpt_load_path must be set\")\n",
    "    model = src.Model(**vars(cfg.model))\n",
    "    src.Trainer.ckptLoader_(model, cfg.trainer.ckpt_load_path).to(device)\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def _loss_shape(x: torch.Tensor, y: torch.Tensor, cfg) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(  # (B,)\n",
    "        input=torch.stack([\n",
    "            torch.roll(x, shifts=s, dims=-1)\n",
    "            for s in range(-cfg.runner.K, cfg.runner.K + 1)\n",
    "        ], dim=1)[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        target=y.unsqueeze(1).expand(\n",
    "            (-1, 2 * cfg.runner.K + 1, -1)\n",
    "        )[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        reduction=\"none\",\n",
    "    ).mean(dim=-1).min(dim=-1).values.mean()\n",
    "\n",
    "\n",
    "def _loss_min(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.min(dim=-1).values, y.min(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _loss_max(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.max(dim=-1).values, y.max(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _weight_tag(w_min: float, w_max: float) -> str:\n",
    "    def fmt(v: float) -> str:\n",
    "        txt = f\"{v:.6f}\"\n",
    "        txt = txt.rstrip(\"0\").rstrip(\".\") if \".\" in txt else txt\n",
    "        return txt.replace(\".\", \"p\")\n",
    "\n",
    "    return f\"wmin{fmt(w_min)}_wmax{fmt(w_max)}\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    _set_seed_and_precision()\n",
    "    device = _device()\n",
    "\n",
    "    cfg: config.Config = getattr(cfg, config_name)()\n",
    "    data = src.DataModule(**vars(cfg.data))\n",
    "    data.setup()\n",
    "\n",
    "    profile = data.profile.copy()\n",
    "    split_mask = profile[\"split\"].isin([1, 2])\n",
    "    subjects = sorted(profile.loc[split_mask, \"subject\"].unique())\n",
    "\n",
    "    weight_pairs: list[tuple[float, float]] = [\n",
    "        (1e-6, 1 - 1e-6),\n",
    "        (0.1, 0.9),\n",
    "        (0.5, 0.5),\n",
    "        (0.9, 0.1),\n",
    "        (1 - 1e-6, 1e-6),\n",
    "    ]\n",
    "\n",
    "    out_rows: list[pd.DataFrame] = []\n",
    "    subjects_bar = tqdm.tqdm(subjects, desc=\"Subjects\", position=0)\n",
    "    for subject in subjects_bar:\n",
    "        subjects_bar.set_postfix_str(subject)\n",
    "        subject_profile = profile.loc[profile[\"subject\"] == subject]\n",
    "        cond_eq1_mask = subject_profile[\"condition\"] == 1\n",
    "        cond_ne1_mask = subject_profile[\"condition\"] != 1\n",
    "        if (not cond_eq1_mask.any()) or (not cond_ne1_mask.any()):\n",
    "            subjects_bar.write(\n",
    "                f\"Skip {subject}: missing condition 1 or condition != 1 data\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        base_out = subject_profile.loc[cond_ne1_mask].copy().reset_index(drop=True)\n",
    "        true_filled = False\n",
    "\n",
    "        weight_bar = tqdm.tqdm(\n",
    "            weight_pairs, desc=\"Weight sets\", position=1, leave=False\n",
    "        )\n",
    "        for w_min, w_max in weight_bar:\n",
    "            weight_bar.set_postfix({\"w_min\": w_min, \"w_max\": w_max})\n",
    "            cfg.objective.weight_min = w_min\n",
    "            cfg.objective.weight_max = w_max\n",
    "\n",
    "            model = _load_model(cfg, device)\n",
    "\n",
    "            # backbone outputs for finetuning\n",
    "            x_train, y_train = [], []\n",
    "            for batch in data.train_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_train.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_train.append(batch[2])\n",
    "            x_train = torch.cat(x_train, dim=0)\n",
    "            y_train = torch.cat(y_train, dim=0)\n",
    "\n",
    "            x_valid, y_valid = [], []\n",
    "            for batch in data.val_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_valid.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_valid.append(batch[2])\n",
    "            x_valid = torch.cat(x_valid, dim=0)\n",
    "            y_valid = torch.cat(y_valid, dim=0)\n",
    "\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.objective.lr)\n",
    "\n",
    "            epoch_bar = tqdm.trange(\n",
    "                cfg.trainer.max_epochs, desc=\"Epochs\", position=2, leave=False\n",
    "            )\n",
    "            for _ in epoch_bar:\n",
    "                model.train()\n",
    "                x = model.forwardAdapter(x_train)\n",
    "                train_loss_shape = _loss_shape(x, y_train, cfg)\n",
    "                train_loss_min = _loss_min(x, y_train)\n",
    "                train_loss_max = _loss_max(x, y_train)\n",
    "                train_loss = (\n",
    "                    cfg.objective.weight_shape * train_loss_shape\n",
    "                    + cfg.objective.weight_min * train_loss_min\n",
    "                    + cfg.objective.weight_max * train_loss_max\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    x_val = model.forwardAdapter(x_valid)\n",
    "                    valid_loss_shape = _loss_shape(x_val, y_valid, cfg)\n",
    "                    valid_loss_min = _loss_min(x_val, y_valid)\n",
    "                    valid_loss_max = _loss_max(x_val, y_valid)\n",
    "                    valid_loss = (\n",
    "                        cfg.objective.weight_shape * valid_loss_shape\n",
    "                        + cfg.objective.weight_min * valid_loss_min\n",
    "                        + cfg.objective.weight_max * valid_loss_max\n",
    "                    )\n",
    "                epoch_bar.set_postfix(\n",
    "                    {\n",
    "                        \"train\": float(train_loss),\n",
    "                        \"valid\": float(valid_loss),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # prediction on this subject (all conditions), then keep condition != 1\n",
    "            model.eval()\n",
    "            result_batches = []\n",
    "            for batch in data.test_dataloader(subject=subject):\n",
    "                x, channel_idx, y = batch\n",
    "                x, channel_idx, y = x.to(device), channel_idx.to(device), y.to(device)\n",
    "                with torch.no_grad():\n",
    "                    x_pred = model.forwardRegression(\n",
    "                        x, channel_idx, adapter=True\n",
    "                    )\n",
    "                result_batches.append(torch.cat([\n",
    "                    x.detach().cpu(),                       # (B, 4, T)\n",
    "                    y.detach().cpu().unsqueeze(1),          # (B, 1, T)\n",
    "                    x_pred.detach().cpu().unsqueeze(1),     # (B, 1, T)\n",
    "                ], dim=1))\n",
    "            result = torch.cat(result_batches, dim=0)       # (N, 5, T)\n",
    "            result = torch.cat([\n",
    "                result,\n",
    "                data.denormalize(result[:, 3, :]).unsqueeze(1),\n",
    "                data.denormalize(result[:, 4, :]).unsqueeze(1),\n",
    "            ], dim=1).detach().cpu()                        # (N, 7, T)\n",
    "\n",
    "            true_min = result[:, 5].min(dim=1).values.numpy()\n",
    "            true_max = result[:, 5].max(dim=1).values.numpy()\n",
    "            pred_min = result[:, 6].min(dim=1).values.numpy()\n",
    "            pred_max = result[:, 6].max(dim=1).values.numpy()\n",
    "\n",
    "            cond_ne1_array = cond_ne1_mask.to_numpy()\n",
    "            if not true_filled:\n",
    "                base_out[\"TrueMinBP\"] = true_min[cond_ne1_array]\n",
    "                base_out[\"TrueMaxBP\"] = true_max[cond_ne1_array]\n",
    "                true_filled = True\n",
    "\n",
    "            tag = _weight_tag(w_min, w_max)\n",
    "            base_out[f\"PredMinBP_{tag}\"] = pred_min[cond_ne1_array]\n",
    "            base_out[f\"PredMaxBP_{tag}\"] = pred_max[cond_ne1_array]\n",
    "\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        out_rows.append(base_out)\n",
    "\n",
    "    if not out_rows:\n",
    "        print(\"No subjects processed; nothing saved.\")\n",
    "        return\n",
    "\n",
    "    out_df = pd.concat(out_rows, axis=0).reset_index(drop=True)\n",
    "    out_dir = Path(\"data/presentation/ResultFintune\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / \"profile.csv\"\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved aggregated profile to {out_path} (rows={len(out_df)})\")\n",
    "\n",
    "# Ensure the working directory is the repo root so relative paths resolve\n",
    "os.chdir(Path(__file__).resolve().parents[1])\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "现在，趁着代码在跑，帮我写一个能分析这个profile的脚本。\n",
    "\n",
    "我现在对于最终整体的MAE是多少非常感兴趣。那有两种算法。第一种算法是所有sample用同一个parameter set的情况下，最终的MAE。注意，min和max分别用不同parameter set：一个parameter set让min的MAE最低，一个parameter set让max的MAE最低。我们要求的只是同一个parameter set access  subject/samples。\n",
    "\n",
    "请分别告诉我min和max的哪个parameter set能达到最好的MAE，最好的MAE是多少？然后请visualize一下per subject的MAE。然后visualize一下所有sample画在的，横坐标是prediction，纵坐标是group truth。可以color by subject。\n",
    "\n",
    "\n",
    "第二种算法是，每个subject的min和max我们都用最好的那个parameter set的prediction value当作最终的。剩下的analysis和第一种算法一样，也告诉我最好的MAE多少，visualize一下per subject MAE，还有visulize一下所有sample画在一起的，横坐标是prediction BP，纵坐标是group truth。可以color by subject。注意visulize的时候min和max要分开。\n",
    "\n",
    "请写在script/temp.ipynb里面，方便我看所有的图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import dataclasses\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import src\n",
    "\n",
    "# Which config to use\n",
    "config_name = \"Finetune\"\n",
    "\n",
    "\n",
    "def _device() -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "def _set_seed_and_precision() -> None:\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "    lightning.seed_everything(42, workers=True, verbose=False)\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*MPS.*fallback.*\")\n",
    "\n",
    "\n",
    "def _load_model(cfg: config.Config, device: str) -> src.Model:\n",
    "    if cfg.trainer.ckpt_load_path is None:\n",
    "        raise ValueError(\"config.trainer.ckpt_load_path must be set\")\n",
    "    model = src.Model(**vars(cfg.model))\n",
    "    src.Trainer.ckptLoader_(model, cfg.trainer.ckpt_load_path).to(device)\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def _loss_shape(x: torch.Tensor, y: torch.Tensor, cfg) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(  # (B,)\n",
    "        input=torch.stack([\n",
    "            torch.roll(x, shifts=s, dims=-1)\n",
    "            for s in range(-cfg.runner.K, cfg.runner.K + 1)\n",
    "        ], dim=1)[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        target=y.unsqueeze(1).expand(\n",
    "            (-1, 2 * cfg.runner.K + 1, -1)\n",
    "        )[:, :, cfg.runner.K:-cfg.runner.K],\n",
    "        reduction=\"none\",\n",
    "    ).mean(dim=-1).min(dim=-1).values.mean()\n",
    "\n",
    "\n",
    "def _loss_min(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.min(dim=-1).values, y.min(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _loss_max(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.nn.functional.smooth_l1_loss(\n",
    "        x.max(dim=-1).values, y.max(dim=-1).values\n",
    "    )\n",
    "\n",
    "\n",
    "def _weight_tag(w_min: float, w_max: float) -> str:\n",
    "    def fmt(v: float) -> str:\n",
    "        txt = f\"{v:.6f}\"\n",
    "        txt = txt.rstrip(\"0\").rstrip(\".\") if \".\" in txt else txt\n",
    "        return txt.replace(\".\", \"p\")\n",
    "\n",
    "    return f\"wmin{fmt(w_min)}_wmax{fmt(w_max)}\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    _set_seed_and_precision()\n",
    "    device = _device()\n",
    "\n",
    "    config: src.config.Config = getattr(src.config, config_name)()\n",
    "    data = src.data.DataModule(**vars(config.data))\n",
    "    data.setup()\n",
    "\n",
    "    profile = data.profile.copy()\n",
    "    split_mask = profile[\"split\"].isin([1, 2])\n",
    "    subjects = sorted(profile.loc[split_mask, \"subject\"].unique())\n",
    "\n",
    "    weight_pairs: list[tuple[float, float]] = [\n",
    "        (1e-6, 1 - 1e-6),\n",
    "        (0.1, 0.9),\n",
    "        (0.5, 0.5),\n",
    "        (0.9, 0.1),\n",
    "        (1 - 1e-6, 1e-6),\n",
    "    ]\n",
    "\n",
    "    out_rows: list[pd.DataFrame] = []\n",
    "    subjects_bar = tqdm.tqdm(subjects, desc=\"Subjects\", position=0)\n",
    "    for subject in subjects_bar:\n",
    "        subjects_bar.set_postfix_str(subject)\n",
    "        subject_profile = profile.loc[profile[\"subject\"] == subject]\n",
    "        cond_eq1_mask = subject_profile[\"condition\"] == 1\n",
    "        cond_ne1_mask = subject_profile[\"condition\"] != 1\n",
    "        if (not cond_eq1_mask.any()) or (not cond_ne1_mask.any()):\n",
    "            subjects_bar.write(\n",
    "                f\"Skip {subject}: missing condition 1 or condition != 1 data\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        base_out = subject_profile.loc[cond_ne1_mask].copy().reset_index(drop=True)\n",
    "        true_filled = False\n",
    "\n",
    "        weight_bar = tqdm.tqdm(\n",
    "            weight_pairs, desc=\"Weight sets\", position=1, leave=False\n",
    "        )\n",
    "        for w_min, w_max in weight_bar:\n",
    "            weight_bar.set_postfix({\"w_min\": w_min, \"w_max\": w_max})\n",
    "            config.objective.weight_min = w_min\n",
    "            config.objective.weight_max = w_max\n",
    "\n",
    "            model = _load_model(config, device)\n",
    "\n",
    "            # backbone outputs for finetuning\n",
    "            x_train, y_train = [], []\n",
    "            for batch in data.train_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_train.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_train.append(batch[2])\n",
    "            x_train = torch.cat(x_train, dim=0)\n",
    "            y_train = torch.cat(y_train, dim=0)\n",
    "\n",
    "            x_valid, y_valid = [], []\n",
    "            for batch in data.val_dataloader(subject=subject):\n",
    "                batch = [b.to(device) for b in batch]\n",
    "                with torch.no_grad():\n",
    "                    x_valid.append(model.forward(batch[0], batch[1], pool_dim=1))\n",
    "                y_valid.append(batch[2])\n",
    "            x_valid = torch.cat(x_valid, dim=0)\n",
    "            y_valid = torch.cat(y_valid, dim=0)\n",
    "\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=config.objective.lr)\n",
    "\n",
    "            epoch_bar = tqdm.trange(\n",
    "                config.trainer.max_epochs, desc=\"Epochs\", position=2, leave=False\n",
    "            )\n",
    "            for _ in epoch_bar:\n",
    "                model.train()\n",
    "                x = model.forwardAdapter(x_train)\n",
    "                train_loss_shape = _loss_shape(x, y_train, config)\n",
    "                train_loss_min = _loss_min(x, y_train)\n",
    "                train_loss_max = _loss_max(x, y_train)\n",
    "                train_loss = (\n",
    "                    config.objective.weight_shape * train_loss_shape\n",
    "                    + config.objective.weight_min * train_loss_min\n",
    "                    + config.objective.weight_max * train_loss_max\n",
    "                )\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    x_val = model.forwardAdapter(x_valid)\n",
    "                    valid_loss_shape = _loss_shape(x_val, y_valid, config)\n",
    "                    valid_loss_min = _loss_min(x_val, y_valid)\n",
    "                    valid_loss_max = _loss_max(x_val, y_valid)\n",
    "                    valid_loss = (\n",
    "                        config.objective.weight_shape * valid_loss_shape\n",
    "                        + config.objective.weight_min * valid_loss_min\n",
    "                        + config.objective.weight_max * valid_loss_max\n",
    "                    )\n",
    "                epoch_bar.set_postfix(\n",
    "                    {\n",
    "                        \"train\": float(train_loss),\n",
    "                        \"valid\": float(valid_loss),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # prediction on this subject (all conditions), then keep condition != 1\n",
    "            model.eval()\n",
    "            result_batches = []\n",
    "            for batch in data.test_dataloader(subject=subject):\n",
    "                x, channel_idx, y = batch\n",
    "                x, channel_idx, y = x.to(device), channel_idx.to(device), y.to(device)\n",
    "                with torch.no_grad():\n",
    "                    x_pred = model.forwardRegressionAdapter(\n",
    "                        x, channel_idx\n",
    "                    )\n",
    "                result_batches.append(torch.cat([\n",
    "                    x.detach().cpu(),                       # (B, 4, T)\n",
    "                    y.detach().cpu().unsqueeze(1),          # (B, 1, T)\n",
    "                    x_pred.detach().cpu().unsqueeze(1),     # (B, 1, T)\n",
    "                ], dim=1))\n",
    "            result = torch.cat(result_batches, dim=0)       # (N, 5, T)\n",
    "            result = torch.cat([\n",
    "                result,\n",
    "                data.denormalize(result[:, 3, :]).unsqueeze(1),\n",
    "                data.denormalize(result[:, 4, :]).unsqueeze(1),\n",
    "            ], dim=1).detach().cpu()                        # (N, 7, T)\n",
    "\n",
    "            true_min = result[:, 5].min(dim=1).values.numpy()\n",
    "            true_max = result[:, 5].max(dim=1).values.numpy()\n",
    "            pred_min = result[:, 6].min(dim=1).values.numpy()\n",
    "            pred_max = result[:, 6].max(dim=1).values.numpy()\n",
    "\n",
    "            cond_ne1_array = cond_ne1_mask.to_numpy()\n",
    "            if not true_filled:\n",
    "                base_out[\"TrueMinBP\"] = true_min[cond_ne1_array]\n",
    "                base_out[\"TrueMaxBP\"] = true_max[cond_ne1_array]\n",
    "                true_filled = True\n",
    "\n",
    "            tag = _weight_tag(w_min, w_max)\n",
    "            base_out[f\"PredMinBP_{tag}\"] = pred_min[cond_ne1_array]\n",
    "            base_out[f\"PredMaxBP_{tag}\"] = pred_max[cond_ne1_array]\n",
    "\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        out_rows.append(base_out)\n",
    "\n",
    "    if not out_rows:\n",
    "        print(\"No subjects processed; nothing saved.\")\n",
    "        return\n",
    "\n",
    "    out_df = pd.concat(out_rows, axis=0).reset_index(drop=True)\n",
    "    out_dir = Path(\"data/presentation/ResultFintune\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / \"profile.csv\"\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved aggregated profile to {out_path} (rows={len(out_df)})\")\n",
    "\n",
    "\n",
    "# Ensure the working directory is the repo root so relative paths resolve\n",
    "os.chdir(Path(__file__).resolve().parents[1])\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "px.defaults.template = \"plotly_white\"\n",
    "px.defaults.width = 1250\n",
    "px.defaults.height = 600\n",
    "\n",
    "def mae(y_true, y_pred) -> float:\n",
    "    \"\"\"Nan-tolerant MAE.\"\"\"\n",
    "    diff = np.abs(np.asarray(y_true) - np.asarray(y_pred))\n",
    "    return float(np.nanmean(diff))\n",
    "\n",
    "output_dir = Path(\"data/presentation/ResultFintune\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path = output_dir / \"profile.csv\"\n",
    "profile = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect available parameter sets (tags)\n",
    "pred_min_cols = [c for c in profile.columns if c.startswith(\"PredMinBP_\")]\n",
    "pred_max_cols = [c for c in profile.columns if c.startswith(\"PredMaxBP_\")]\n",
    "tags_min = [c.removeprefix(\"PredMinBP_\") for c in pred_min_cols]\n",
    "tags_max = [c.removeprefix(\"PredMaxBP_\") for c in pred_max_cols]\n",
    "assert tags_min, \"No PredMinBP_* columns found\"\n",
    "assert tags_max, \"No PredMaxBP_* columns found\"\n",
    "tags_min, tags_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strategy 1: global best parameter set (separate best for min vs. max) ---\n",
    "def best_global(true_col: str, prefix: str, tags: list[str]):\n",
    "    scores = {\n",
    "        tag: mae(profile[true_col], profile[f\"{prefix}{tag}\"])\n",
    "        for tag in tags\n",
    "    }\n",
    "    best_tag = min(scores, key=scores.get)\n",
    "    return best_tag, scores\n",
    "\n",
    "best_min_tag, min_scores = best_global(\"TrueMinBP\", \"PredMinBP_\", tags_min)\n",
    "best_max_tag, max_scores = best_global(\"TrueMaxBP\", \"PredMaxBP_\", tags_max)\n",
    "best_min_mae = min_scores[best_min_tag]\n",
    "best_max_mae = max_scores[best_max_tag]\n",
    "\n",
    "metrics_text = (\n",
    "    f\"Global best (min): {best_min_tag} -> MAE = {best_min_mae:.4f}\\n\"\n",
    "    f\"Global best (max): {best_max_tag} -> MAE = {best_max_mae:.4f}\"\n",
    ")\n",
    "metrics_path = output_dir / \"01GlobalBestParas.txt\"\n",
    "metrics_path.write_text(metrics_text + \"\\n\")\n",
    "print(f\"Wrote global metrics to {metrics_path}\")\n",
    "\n",
    "# Per-sample errors for box plots\n",
    "err_rows = []\n",
    "for subj, df_sub in profile.groupby(\"subject\"):\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"diastolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMinBP\"] - df_sub[f\"PredMinBP_{best_min_tag}\"])\n",
    "    }))\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"systolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMaxBP\"] - df_sub[f\"PredMaxBP_{best_max_tag}\"])\n",
    "    }))\n",
    "sample_err_global = pd.concat(err_rows, ignore_index=True)\n",
    "\n",
    "fig_box_global = px.box(\n",
    "    sample_err_global, x=\"subject\", y=\"error\", color=\"metric\",\n",
    "    points=\"suspectedoutliers\", title=\"Per-sample error (global best tags)\",\n",
    "    labels={\"error\": \"|Pred-True|\", \"subject\": \"Subject\"}\n",
    ")\n",
    "\n",
    "fig_box_global.update_traces(marker=dict(size=3), whiskerwidth=0)\n",
    "fig_box_global.update_yaxes(type=\"log\", range=[0, 2])\n",
    "fig_box_global.write_image(output_dir / \"01GlobalBestParas.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994be8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strategy 2: per-subject best parameter set (separate for min vs. max) ---\n",
    "def best_tags_per_subject(true_col: str, prefix: str, tags: list[str]):\n",
    "    out = {}\n",
    "    for subj, df_sub in profile.groupby(\"subject\"):\n",
    "        scores = {\n",
    "            tag: mae(df_sub[true_col], df_sub[f\"{prefix}{tag}\"])\n",
    "            for tag in tags\n",
    "        }\n",
    "        out[subj] = min(scores, key=scores.get)\n",
    "    return out\n",
    "\n",
    "best_min_by_subj = best_tags_per_subject(\"TrueMinBP\", \"PredMinBP_\", tags_min)\n",
    "best_max_by_subj = best_tags_per_subject(\"TrueMaxBP\", \"PredMaxBP_\", tags_max)\n",
    "\n",
    "# Build columns with per-subject best predictions\n",
    "profile = profile.copy()\n",
    "profile[\"PredMinBP_best_subject\"] = np.nan\n",
    "profile[\"PredMaxBP_best_subject\"] = np.nan\n",
    "\n",
    "for subj, tag in best_min_by_subj.items():\n",
    "    mask = profile[\"subject\"] == subj\n",
    "    profile.loc[mask, \"PredMinBP_best_subject\"] = profile.loc[mask, f\"PredMinBP_{tag}\"]\n",
    "for subj, tag in best_max_by_subj.items():\n",
    "    mask = profile[\"subject\"] == subj\n",
    "    profile.loc[mask, \"PredMaxBP_best_subject\"] = profile.loc[mask, f\"PredMaxBP_{tag}\"]\n",
    "\n",
    "overall_min_mae = mae(profile[\"TrueMinBP\"], profile[\"PredMinBP_best_subject\"])\n",
    "overall_max_mae = mae(profile[\"TrueMaxBP\"], profile[\"PredMaxBP_best_subject\"])\n",
    "metrics_text = (\n",
    "    f\"Per-subject best (min): MAE = {overall_min_mae:.4f}\\n\"\n",
    "    f\"Per-subject best (max): MAE = {overall_max_mae:.4f}\"\n",
    ")\n",
    "metrics_path = output_dir / \"02SubjectBestParas.txt\"\n",
    "metrics_path.write_text(metrics_text + \"\\n\")\n",
    "print(f\"Wrote subject-level metrics to {metrics_path}\")\n",
    "\n",
    "# Per-sample errors for box plots (subject-specific best)\n",
    "err_rows = []\n",
    "for subj, df_sub in profile.groupby(\"subject\"):\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"diastolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMinBP\"] - df_sub[\"PredMinBP_best_subject\"]),\n",
    "    }))\n",
    "    err_rows.append(pd.DataFrame({\n",
    "        \"subject\": subj,\n",
    "        \"metric\": \"systolic\",\n",
    "        \"error\": np.abs(df_sub[\"TrueMaxBP\"] - df_sub[\"PredMaxBP_best_subject\"]),\n",
    "    }))\n",
    "sample_err_subject = pd.concat(err_rows, ignore_index=True)\n",
    "\n",
    "fig_box_subj = px.box(\n",
    "    sample_err_subject, x=\"subject\", y=\"error\", color=\"metric\",\n",
    "    points=\"suspectedoutliers\", title=\"Per-sample error (subject-specific best tags)\",\n",
    "    labels={\"error\": \"|Pred-True|\", \"subject\": \"Subject\"}\n",
    ")\n",
    "\n",
    "fig_box_subj.update_traces(marker=dict(size=3), whiskerwidth=0)\n",
    "fig_box_subj.update_yaxes(type=\"log\", range=[0, 2])\n",
    "fig_box_subj.write_image(output_dir / \"02SubjectBestParas.png\")\n",
    "\n",
    "# Quick look at which tag won per subject (optional table)\n",
    "pd.DataFrame({\n",
    "    \"subject\": list(best_min_by_subj.keys()),\n",
    "    \"best_min_tag\": list(best_min_by_subj.values()),\n",
    "    \"best_max_tag\": [best_max_by_subj[s] for s in best_min_by_subj.keys()],\n",
    "}).sort_values(\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: remove extreme errors (possible bad ground truth) and recompute\n",
    "pred_min_col = \"PredMinBP_best_subject\"\n",
    "pred_max_col = \"PredMaxBP_best_subject\"\n",
    "\n",
    "df_err = profile.copy()\n",
    "df_err[\"err_diastolic\"] = np.abs(df_err[\"TrueMinBP\"] - df_err[pred_min_col])\n",
    "df_err[\"err_systolic\"] = np.abs(df_err[\"TrueMaxBP\"] - df_err[pred_max_col])\n",
    "\n",
    "def filter_outliers_iqr(df: pd.DataFrame, cols: list[str], k: float = 1.5, max_pct: float = 0.99):\n",
    "    \"\"\"IQR + percentile cap: keep rows where each col <= min(q3 + k*IQR, pct(max_pct)).\"\"\"\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    thresholds: dict[str, float] = {}\n",
    "    for col in cols:\n",
    "        s = df[col].dropna()\n",
    "        if s.empty:\n",
    "            thresholds[col] = np.nan\n",
    "            continue\n",
    "        q1, q3 = s.quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        upper_iqr = q3 + k * iqr\n",
    "        upper_pct = s.quantile(max_pct)\n",
    "        upper = float(min(upper_iqr, upper_pct))\n",
    "        thresholds[col] = upper\n",
    "        mask &= df[col] <= upper\n",
    "    return df[mask].copy(), thresholds, mask\n",
    "\n",
    "filtered, thresholds, keep_mask = filter_outliers_iqr(\n",
    "    df_err, [\"err_diastolic\", \"err_systolic\"], k=1.5, max_pct=0.99\n",
    ")\n",
    "\n",
    "summary_lines = [\n",
    "    f\"Thresholds (abs error): {thresholds}\",\n",
    "    (\n",
    "        f\"Kept {len(filtered)} of {len(df_err)} samples (\"\n",
    "        f\"{keep_mask.mean()*100:.1f}%); removed {len(df_err) - len(filtered)}\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "filtered_min_mae = mae(filtered[\"TrueMinBP\"], filtered[pred_min_col])\n",
    "filtered_max_mae = mae(filtered[\"TrueMaxBP\"], filtered[pred_max_col])\n",
    "summary_lines.append(\n",
    "    \"Filtered overall MAE (diastolic, systolic): \"\n",
    "    f\"({filtered_min_mae:.4f}, {filtered_max_mae:.4f})\"\n",
    ")\n",
    "\n",
    "metrics_path = output_dir / \"03SubjectBestParasThresholds.txt\"\n",
    "metrics_path.write_text(\"\\n\".join(summary_lines) + \"\\n\")\n",
    "print(f\"Wrote filtered metrics to {metrics_path}\")\n",
    "\n",
    "# Box plot on filtered data (box + suspected outliers on same line)\n",
    "err_long = pd.concat([\n",
    "    filtered[[\"subject\", \"err_diastolic\"]].rename(columns={\"err_diastolic\": \"error\"}).assign(metric=\"diastolic\"),\n",
    "    filtered[[\"subject\", \"err_systolic\"]].rename(columns={\"err_systolic\": \"error\"}).assign(metric=\"systolic\"),\n",
    "])\n",
    "fig_box_filtered = px.box(\n",
    "    err_long, x=\"subject\", y=\"error\", color=\"metric\",\n",
    "    points=\"suspectedoutliers\",\n",
    "    title=\"Per-sample error after outlier removal (subject-specific best)\",\n",
    "    labels={\"error\": \"|Pred-True|\", \"subject\": \"Subject\"}\n",
    ")\n",
    "fig_box_filtered.update_traces(marker=dict(size=3), whiskerwidth=0)\n",
    "fig_box_filtered.update_yaxes(type=\"log\", range=[0, 2])\n",
    "fig_box_filtered.write_image(output_dir / \"03SubjectBestParasThresholds.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scos-bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
